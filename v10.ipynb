{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用python库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from talib.abstract import *\n",
    "import seaborn as sbn\n",
    "sbn.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable\n",
    "timesteps = 8\n",
    "batch_size = 16\n",
    "units = 32\n",
    "data_dim = 0\n",
    "div_class = [-0.003, 0.003]\n",
    "# div_class = [-0.5, -0.3, -0.1, 0.1, 0.3, 0.5]\n",
    "num_classes = 3\n",
    "\n",
    "idx_dict = {'中证500': 990905}\n",
    "# idx_dict = {'上证50': 999987, '沪深300': 300, '中证500': 990905, '中小板指': 399005, '创业板指': 399006}\n",
    "\n",
    "idxes = []\n",
    "for name in idx_dict:\n",
    "    idxes.append(idx_dict[name])\n",
    "print('idxes: {0}'.format(idxes)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_load():\n",
    "    data_dir = '../data/'\n",
    "    day_index1 = data_dir + '1day/index/2000_2009.csv'\n",
    "    day_index2 = data_dir + '1day/index/2010_2016.csv'\n",
    "    data1 = pd.read_csv(day_index1,encoding='gbk', parse_dates=['date'])\n",
    "    data2 = pd.read_csv(day_index2,encoding='gbk', parse_dates=['date'])\n",
    "    data = pd.concat([data1, data2])\n",
    "    data.set_index(['code', 'date'], inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_all = data_load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据清理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_clean(data):\n",
    "    new_data = pd.DataFrame()\n",
    "    for column in ['open', 'high', 'low', 'close']:\n",
    "        new_data[column] = data[column] / 10000.0\n",
    "\n",
    "    # new_data.dropna(inplace=True)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据转换"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 转换函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 阴阳线\n",
    "def stick_type(x):\n",
    "    stick_type = -1\n",
    "    if x['close'] >= x['open']:\n",
    "        stick_type = 1\n",
    "    return stick_type\n",
    "\n",
    "# 上引线\n",
    "def up_line(x):\n",
    "    return x['high'] - x[['open','close']].max()\n",
    "\n",
    "# 下引线\n",
    "def down_line(x):\n",
    "    return -(x[['open','close']].min() - x['low'])\n",
    "\n",
    "# 实体长度\n",
    "def body_size(x):\n",
    "    return x['close'] - x['open']\n",
    "\n",
    "def range_to_class(x):\n",
    "    cls = []\n",
    "    if x >= 0:\n",
    "        for i in range(num_classes):\n",
    "            if i == x:\n",
    "                cls.append(1.0)\n",
    "            else:\n",
    "                cls.append(0.0)\n",
    "    else:\n",
    "        print(x)\n",
    "        print(\"Error: n less than 0\")\n",
    "    return cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# std_ration = 0.5\n",
    "# def range_to_class(x):\n",
    "#     df = pd.DataFrame(index=x.index)\n",
    "#     df['close'] = x['close']\n",
    "#     df['next_close'] = df['close'].shift(-1)\n",
    "#     df['mean'] = df['close'].rolling(window=60, center=False, min_periods=60).mean()\n",
    "#     df['std'] = df['close'].rolling(window=60, center=False, min_periods=60).std()\n",
    "#     df.fillna(method='bfill', inplace=True)\n",
    "#     df['down'] = df['mean'] - std_ration * df['std']\n",
    "#     df['up'] = df['mean'] + std_ration * df['std']\n",
    "#     df['class'] = np.nan\n",
    "#     df.loc[df['next_close'] > df['up'], 'class'] = 2\n",
    "#     df.loc[df['next_close'] < df['down'], 'class'] = 0\n",
    "#     cond = (df['next_close'] <= df['up']) & (df['next_close'] >= df['down'])\n",
    "#     df.loc[cond, 'class'] = 1\n",
    "#     # last row has no next_close\n",
    "#     new_data.dropna(inplace=True)\n",
    "    \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "std_ration = 0.01\n",
    "def data_transform(data):\n",
    "    new_data = pd.DataFrame()\n",
    "    pre_close = data['close'].shift(1)\n",
    "    for column in ['open', 'high', 'low', 'close']:\n",
    "        new_data[column] = (data[column] - pre_close) / pre_close\n",
    "        \n",
    "    # add new feature\n",
    "    # new_data['stick_type'] = new_data.apply(stick_type, axis=1)\n",
    "    new_data['up_line'] = new_data.apply(up_line, axis=1)\n",
    "    new_data['down_line'] = new_data.apply(down_line, axis=1)\n",
    "    new_data['close_open'] = new_data.apply(body_size, axis=1)\n",
    "    new_data.drop(['open', 'high', 'low'], axis=1, inplace=True)\n",
    "    \n",
    "    # ma\n",
    "    # ma_lines = [5, 10, 20, 30]\n",
    "    ma_lines = [5]\n",
    "    pd_ma = pd.DataFrame(index=data.index)\n",
    "    for ma_line in ma_lines:\n",
    "        ma = MA(data.astype({'close': \"double\"}), price='close', timeperiod=ma_line)\n",
    "        pd_ma['ma'+ str(ma_line)] = (ma - data['close']) / data['close']\n",
    "    new_data = pd.concat([new_data, pd_ma], axis=1)\n",
    "    new_data.dropna(inplace=True)\n",
    "    \n",
    "    # macd\n",
    "#     macd = MACD(data.astype({'close': \"double\"}), price='close')\n",
    "#     new_data = pd.concat([new_data, macd], axis=1)\n",
    "#     new_data.dropna(inplace=True)\n",
    "    \n",
    "    # new_data['class'] = new_data.apply(range_to_class, axis=1)\n",
    "    #new_data.dropna(inplace=True)\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    df['close'] = new_data['close']\n",
    "    df['next_close'] = df['close'].shift(-1)\n",
    "    df['mean'] = df['close'].rolling(window=60, center=False, min_periods=60).mean()\n",
    "    df['std'] = df['close'].rolling(window=60, center=False, min_periods=60).std()\n",
    "#     df['mean'] = df['close'].mean()\n",
    "#     df['std'] = df['close'].std()\n",
    "    \n",
    "    df.fillna(method='bfill', inplace=True)\n",
    "    df['down'] = df['mean'] - std_ration * df['std']\n",
    "    df['up'] = df['mean'] + std_ration * df['std']\n",
    "    df['class'] = np.nan\n",
    "    df.loc[df['next_close'] > df['up'], 'class'] = 2\n",
    "    df.loc[df['next_close'] < df['down'], 'class'] = 0\n",
    "    cond = (df['next_close'] <= df['up']) & (df['next_close'] >= df['down'])\n",
    "    df.loc[cond, 'class'] = 1\n",
    "    new_data['class'] = df['class']\n",
    "    # last row has no next_close\n",
    "    new_data.dropna(inplace=True)\n",
    "    \n",
    "    # new_data['class']= new_data['class'].map(range_to_class)\n",
    "        \n",
    "#     # classes\n",
    "#     new_data['class'] = new_data['close'].shift(-1)\n",
    "#     # new_data.dropna(inplace=True)\n",
    "#     new_data.fillna(0, inplace=True)\n",
    "#     new_data['class']= new_data['class'].map(range_to_class)\n",
    "        \n",
    "    # new_data.dropna(inplace=True)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_set(data, codes):\n",
    "    data_set = {}\n",
    "    for code in codes:\n",
    "        query_str = 'code=={0}'.format(code)\n",
    "        data_match = data.query(query_str)\n",
    "        data_cleaned = data_clean(data_match)\n",
    "        data_transformed = data_transform(data_cleaned)\n",
    "        print('code: {0}, data set len: {1}, start at: {2}, end at: {3}'.format(\n",
    "            code, len(data_transformed), data_transformed.index[0],data_transformed.index[-1]))\n",
    "        data_set[code] = data_transformed\n",
    "    return data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = get_data_set(data_all, idxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set[990905].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    new_data = data.copy()\n",
    "    # norm_columns = ['close', 'ma5']\n",
    "    norm_columns = ['close', 'close_open', 'ma5']\n",
    "    # norm_columns = ['open', 'high', 'low', 'close', 'close_open']\n",
    "    # norm_columns = ['open', 'high', 'low', 'close', 'close_open', 'macd', 'macdsignal', 'macdhist']\n",
    "    for column in norm_columns:\n",
    "        new_data[column] = preprocessing.scale(new_data[column])\n",
    "        \n",
    "    updown_line_values = new_data.loc[:,['up_line', 'down_line']].values\n",
    "    updown_line_values_norm = preprocessing.scale(updown_line_values.reshape((-1,1))).reshape((-1, 2))\n",
    "    updown_df = pd.DataFrame(index=new_data.index, columns=['up_line', 'down_line'], data=updown_line_values_norm)\n",
    "    new_data['up_line'] = updown_df['up_line']\n",
    "    new_data['down_line'] = updown_df['down_line']\n",
    "        \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_set_norm = {}\n",
    "for code in data_set:\n",
    "    data_set_norm[code] = normalize(data_set[code])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_norm[990905].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(data, date, timesteps, batch_size):\n",
    "    min_num = int(batch_size) * int(timesteps)\n",
    "    \n",
    "    train_query_str = 'date <= \"{}\"'.format(date)\n",
    "    test_query_str = 'date > \"{}\"'.format(date)\n",
    "    \n",
    "    train = data.query(train_query_str)\n",
    "    test = data.query(test_query_str)\n",
    "    \n",
    "    train_size = len(train)\n",
    "    test_size = len(test)\n",
    "    print('split set to train size: {0}, test size: {1}'.format(train_size, test_size))\n",
    "    \n",
    "    train_batchs = int(train_size / min_num)\n",
    "    test_batchs = int(test_size / min_num)\n",
    "    \n",
    "    if train_batchs > 0:\n",
    "        train = train[-(train_batchs * min_num + 1):-1]\n",
    "    else:\n",
    "        train = None\n",
    "\n",
    "    if test_batchs > 0:\n",
    "        test = test[0:test_batchs * min_num]\n",
    "    else:\n",
    "        test = None\n",
    "    \n",
    "    print(\"train set len: {0}, start at {1}, end at {2}\".format(len(train), train.index.get_level_values('date')[0], train.index.get_level_values('date')[-1]))\n",
    "    print(\"test set len: {0}, start at {1}, end at {2}\".format(len(test), test.index.get_level_values('date')[0], test.index.get_level_values('date')[-1])) \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_set = {}\n",
    "df_test_set = {}\n",
    "\n",
    "for code in data_set_norm:\n",
    "    print('spliting code: {0}'.format(code))\n",
    "    train, test = split_data(data_set_norm[code], '20160620', timesteps=timesteps, batch_size=batch_size)\n",
    "    df_train_set[code] = train\n",
    "    df_test_set[code] = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_set[990905].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_set[990905]['class'].plot.hist(bins=30)\n",
    "df_test_set[990905]['class'].plot.hist(bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据重整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_reform(data, batch_size, timesteps):\n",
    "    data['class']= data['class'].map(range_to_class)\n",
    "    data_values = data.values\n",
    "    \n",
    "    print(\"shape: {0}\".format(data_values.shape))\n",
    "    size = len(data_values)\n",
    "    if size % (int(batch_size) * int(timesteps)) != 0:\n",
    "        print(\"data size not match, size: {0}, batch_size: {1}, timesteps: {2}\".format(size, batch_size, timesteps))\n",
    "        return None, None\n",
    "   \n",
    "    X, Y0 = data_values[:, :-1], data_values[:, -1]\n",
    "    \n",
    "    X = X.reshape((-1, timesteps, X.shape[1]))\n",
    "    \n",
    "    Y = np.array([np.array(y) for y in Y0])\n",
    "       \n",
    "    Y = Y.reshape((-1, timesteps, Y.shape[1]))\n",
    "    \n",
    "    print(\"X.shape: {0} Y.shape: {1}\".format(X.shape, Y.shape))\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = {}\n",
    "test_set = {}\n",
    "\n",
    "for code in df_train_set:\n",
    "    print(code)\n",
    "    train_set[code] = data_reform(df_train_set[code], batch_size, timesteps)\n",
    "                                  \n",
    "for code in df_test_set:\n",
    "    test_set[code] = data_reform(df_test_set[code], batch_size, timesteps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data_all = data_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# idx_dict = {'上证50': 999987, '沪深300': 300, '中证500': 990905, '中小板指': 399005, '创业板指': 399006}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # 确认指数代码\n",
    "# for idx_name in idx_dict:\n",
    "#     print(\"name: {0}\".format(idx_name))\n",
    "#     Id = data_all[data_all['name'] == idx_name].index.get_level_values('code').unique()\n",
    "#     print(\"Id: {0}\".format(Id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# years = pd.date_range('1/1/2006', periods=11, freq='A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def data_stat(data, years, idx_dict):\n",
    "#     idxes_des = pd.DataFrame()\n",
    "#     for name in idx_dict:\n",
    "#         # print(name)\n",
    "#         code = idx_dict[name]\n",
    "#         query_code = 'code=={0}'.format(code)\n",
    "#         # print(\"query code: {0}\".format(query_code))\n",
    "#         data_code = data.query(query_code)\n",
    "#         data_code_c = data_clean(data_code)\n",
    "#         data_code_t = data_transform(data_code_c)\n",
    "#         idx_des = pd.DataFrame()\n",
    "#         for year in years:\n",
    "#             end_date = year\n",
    "#             begin_date  = year.replace(month=1, day=1)\n",
    "#             query_date = 'date>\"{0}\" & date < \"{1}\"'.format(begin_date, end_date)\n",
    "#             # print(\"query date: {0}\".format(query_date))\n",
    "#             data_code_year = data_code_t.query(query_date)\n",
    "#             describe = data_code_year.close.describe()\n",
    "#             df_describe = describe.to_frame().reset_index()\n",
    "#             df_describe['date'] = year\n",
    "#             idx_des = pd.concat([idx_des, df_describe])\n",
    "#         idx_des = idx_des.pivot(index='date', columns='index', values='close')    \n",
    "#         idx_des['code'] = code\n",
    "#         idxes_des = pd.concat([idxes_des, idx_des])\n",
    "#     return idxes_des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data_stat = data_stat(data_all, years, idx_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data_stat_d = data_stat.drop(['count', 'min', 'max', 'std'],axis=1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# t = data_stat_d.reset_index().set_index(['code', 'date'])\n",
    "# fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(8, 6))\n",
    "# t.loc[999987].plot(ax=axes[0, 0])\n",
    "# t.loc[300].plot(ax=axes[0, 1])\n",
    "# t.loc[990905].plot(ax=axes[1, 0])\n",
    "# t.loc[399005].plot(ax=axes[1, 1])\n",
    "# t.loc[399006].plot(ax=axes[2, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dim = len(data_set_norm[990905].columns) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, timesteps, data_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.layers import LSTM, Dense, Dropout, BatchNormalization, Activation\n",
    "\n",
    "units = 16\n",
    "model = Sequential()\n",
    "# input layer\n",
    "# activation='relu' \n",
    "dropout=0.2\n",
    "# kernel_initializer=\"uniform\"\n",
    "model.add(LSTM(units, stateful=True, return_sequences=True, batch_input_shape=(batch_size, timesteps, data_dim)))\n",
    "# hidden layer\n",
    "model.add(LSTM(units, return_sequences=True, stateful=True, dropout=dropout))\n",
    "# model.add(LSTM(units, return_sequences=True, stateful=True, dropout=dropout))\n",
    "# model.add(LSTM(units, return_sequences=True, stateful=True, dropout=dropout))\n",
    "\n",
    "# 回归问题\n",
    "# # output layer\n",
    "# # model.add(Dense(no_classes, activation='softmax'))\n",
    "# model.add(Dense(1, activation='sigmoid')) # or sigmoid?\n",
    "# # model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# model.compile(optimizer='RMSProp', loss='mse') #mse\n",
    "\n",
    "# 分类问题\n",
    "# output layer\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "# model.add(Dense(num_classes, kernel_initializer=\"uniform\"))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation('softmax'))\n",
    "\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "model.compile(optimizer=RMSprop(0.0005), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from influxdb import InfluxDBClient\n",
    "from influxdb import SeriesHelper\n",
    "host = '183.136.205.102'\n",
    "port = 38086\n",
    "user = 'root'\n",
    "password = 'root'\n",
    "dbname = 'chq'\n",
    "\n",
    "myclient = InfluxDBClient(host, port, user, password, dbname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainid = 1\n",
    "class MySeriesHelper(SeriesHelper):\n",
    "    # Meta class stores time series helper configuration.\n",
    "    class Meta:\n",
    "        # The client should be an instance of InfluxDBClient.\n",
    "        client = myclient\n",
    "        # The series name must be a string. Add dependent fields/tags in curly brackets.\n",
    "        series_name = 'deeplearning.train' + str(trainid)\n",
    "        # Defines all the fields in this time series.\n",
    "        fields = ['loss', 'acc']\n",
    "        # Defines all the tags for the series.\n",
    "        tags = ['dtype', 'code', 'epoch']\n",
    "        # Defines the number of data points to store prior to writing on the wire.\n",
    "        bulk_size = 5\n",
    "        # autocommit must be set to True when using bulk_size\n",
    "        autocommit = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, train_set, test_set, epochs, batch_size):\n",
    "# def train():\n",
    "    for e in range(epochs):\n",
    "        for code in train_set:\n",
    "            model.reset_states()\n",
    "            print(\"epochs: {0}, code: {1}\".format(e, code))\n",
    "            train_X, train_Y = train_set[code]\n",
    "            # print(train_X.shape, train_Y.shape, test_X.shape, test_Y.shape)\n",
    "            # history = model.fit(train_X, train_Y, epochs=100, batch_size=batch_size, validation_data=(test_X, test_Y), verbose=1, shuffle=False)\n",
    "            history = model.fit(train_X, train_Y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n",
    "            model.reset_states()  \n",
    "            # result = {'type': 'train', 'code': code, 'train_loss': (e, history.history['loss'][-1]), 'train_acc': (e, history.history['acc'][-1])}\n",
    "            MySeriesHelper(dtype=\"train\", code=code, epoch = e, loss=history.history['loss'][-1], acc= history.history['acc'][-1])\n",
    "            # print(result)\n",
    "        MySeriesHelper.commit()\n",
    "            # yield result\n",
    "        for code in test_set:\n",
    "            model.reset_states()\n",
    "            test_X, test_Y = test_set[code]\n",
    "            loss_and_metrics = model.evaluate(test_X, test_Y, batch_size=batch_size)\n",
    "            model.reset_states()\n",
    "            # result = {'type': 'test', 'code': code, 'test_loss': (e, loss_and_metrics[0]), 'test_acc': (e, loss_and_metrics[1])}\n",
    "            MySeriesHelper(dtype=\"test\", code=code, epoch = e, loss=loss_and_metrics[0], acc= loss_and_metrics[1])\n",
    "            # print(result)\n",
    "        MySeriesHelper.commit()\n",
    "            # yield result\n",
    "                # print(\"==================================\")\n",
    "                # print(\"loss_and_metrics: {0}\".format(loss_and_metrics))\n",
    "                # print(\"==================================\")\n",
    "\n",
    "#     def data_gen(t=0):\n",
    "#         cnt = 0\n",
    "#         while cnt < 1000:\n",
    "#             cnt += 1\n",
    "#             t += 0.1\n",
    "#             yield t, np.sin(2*np.pi*t) * np.exp(-t/10.)\n",
    "# ani = animation.FuncAnimation(fig, run, train, repeat=False, init_func=init)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "train(model, train_set, test_set, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# history = model.fit(train_X, train_Y, epochs=100, batch_size=batch_size, validation_data=(test_X, test_Y), verbose=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.plot(history.history['loss'], label='train')\n",
    "# plt.plot(history.history['val_loss'], label='test')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.plot(history.history['acc'], label='train')\n",
    "# plt.plot(history.history['val_acc'], label='test')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_X, test_Y = test_set[990905]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_Y=model.predict(x=test_X, batch_size=batch_size)\n",
    "predict_class = np.argmax(predict_Y,axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_test_set(data_all, code):\n",
    "    begin_date = df_test_set[code].index.get_level_values('date')[0]\n",
    "    end_date = df_test_set[code].index.get_level_values('date')[-1]\n",
    "    \n",
    "    query_str = 'code=={0}'.format(code)\n",
    "    data_code = data_all.query(query_str)\n",
    "    data_cleaned = data_clean(data_code)\n",
    "    \n",
    "    cond = (data_cleaned.index.get_level_values('code') == 990905) & (data_cleaned.index.get_level_values('date') <= end_date) & (data_cleaned.index.get_level_values('date') >= begin_date)\n",
    "    test_data_orig = data_cleaned.loc[cond]\n",
    "    \n",
    "    cond = (data_set_norm[code].index.get_level_values('code') == 990905) & (data_set_norm[code].index.get_level_values('date') <= end_date) & (data_set_norm[code].index.get_level_values('date') >= begin_date)\n",
    "    test_data_norm_match = data_set_norm[code].loc[cond]\n",
    "    \n",
    "    compare_data = pd.DataFrame(index=test_data_orig.index)\n",
    "    compare_data['close'] = test_data_orig['close']\n",
    "    compare_data['real_class'] = test_data_norm_match['class']\n",
    "    return compare_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code=990905\n",
    "cmp_predict = compare_test_set(data_all, code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmp_predict['predict_class'] = predict_class.reshape((-1, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp_predict['diff'] = cmp_predict['predict_class'] - cmp_predict['real_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp_predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmp_predict = cmp_predict.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def color(x):\n",
    "    c = 'm'\n",
    "    if x < 0:\n",
    "        c = 'g'\n",
    "    elif x > 0:\n",
    "        c = 'r'\n",
    "    else:\n",
    "        c = 'b'\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmp_predict['color'] = cmp_predict['diff'].map(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cmp_predict.plot(kind='scatter', x='index', y='close', s=60, c=cmp_predict.color, figsize=(8, 6))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp_predict.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp_predict['predict_class'].plot.hist(title='predict_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp_predict['real_class'].plot.hist(title='real_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmp_predict['next_close'] = cmp_predict['close'].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmp_predict['profit'] = cmp_predict['next_close'] - cmp_predict['close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp_predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_profit(x):\n",
    "    profit = 0\n",
    "    if x['predict_class'] == 2:\n",
    "        profit = x['profit']\n",
    "    elif x['predict_class'] == 0:\n",
    "        profit = -x['profit']\n",
    "    else:\n",
    "        profit = 0\n",
    "    return profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp_predict['predict_profit'] = cmp_predict.apply(predict_profit, axis=1)\n",
    "cmp_predict['predict_profit'].cumsum().plot(figsize=(8, 6), color='b', title=)\n",
    "cmp_predict[cmp_predict['predict_class']==2]['predict_profit'].cumsum().plot(color='r')\n",
    "cmp_predict[cmp_predict['predict_class']==0]['predict_profit'].cumsum().plot(color='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 性能评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 类预测比较"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 类分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# column: true_class predict_class\n",
    "def class_compare(df):\n",
    "    return pd.crosstab(df.real_class, df.predict_class, margins=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_compare(cmp_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 利润"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# column: close signal\n",
    "def portfolio_return_ration(df, direction=\"both\"):\n",
    "    def profit(x):\n",
    "        # 归一化\n",
    "        x[x['signal'] < -1]['signal'] = -1\n",
    "        x[x['signal'] > 1]['signal'] = 1\n",
    "\n",
    "        if direction == \"long\":\n",
    "            x[x['signal'] < 0]['signal'] = 0\n",
    "        elif direction == \"short\":\n",
    "            x[x['signal'] > 0]['signal'] = 0\n",
    "            \n",
    "        x['profit'] = x['diff'] * x['signal']\n",
    "        return x\n",
    "\n",
    "    df_tmp = pd.DataFrame()\n",
    "    pre_close = df['close'].shift(1)\n",
    "    df_tmp['diff'] =  df['close'] - pre_close\n",
    "    df_tmp['signal'] = df['signal']\n",
    "    \n",
    "    df_tmp['profit'] = df.apply(profit, axis=1)\n",
    "    return (df_tmp['profit']+1).cumprod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# x = np.linspace(0, 20, 100)\n",
    "# y = np.sin(x)\n",
    "# z = x + 20 * y\n",
    "\n",
    "# scaled_z = (x - x.min())\n",
    "# colors = plt.cm.coolwarm(x)\n",
    "\n",
    "# plt.scatter(x, y, marker='+', edgecolors=colors, s=150, linewidths=4)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
