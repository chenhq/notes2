{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用python库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from talib.abstract import *\n",
    "import seaborn as sbn\n",
    "sbn.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idxes: [990905, 399005, 399006, 999987, 300]\n"
     ]
    }
   ],
   "source": [
    "# Variable\n",
    "timesteps = 32\n",
    "batch_size = 4\n",
    "units = 32\n",
    "data_dim = 4\n",
    "div_class = [-0.003, 0.003]\n",
    "# div_class = [-0.5, -0.3, -0.1, 0.1, 0.3, 0.5]\n",
    "num_classes = 3\n",
    "\n",
    "idx_dict = {'上证50': 999987, '沪深300': 300, '中证500': 990905, '中小板指': 399005, '创业板指': 399006}\n",
    "\n",
    "idxes = []\n",
    "for name in idx_dict:\n",
    "    idxes.append(idx_dict[name])\n",
    "print('idxes: {0}'.format(idxes)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_load():\n",
    "    data_dir = '../data/'\n",
    "    day_index1 = data_dir + '1day/index/2000_2009.csv'\n",
    "    day_index2 = data_dir + '1day/index/2010_2016.csv'\n",
    "    data1 = pd.read_csv(day_index1,encoding='gbk', parse_dates=['date'])\n",
    "    data2 = pd.read_csv(day_index2,encoding='gbk', parse_dates=['date'])\n",
    "    data = pd.concat([data1, data2])\n",
    "    data.set_index(['code', 'date'], inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_all = data_load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据清理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_clean(data):\n",
    "    new_data = pd.DataFrame()\n",
    "    for column in ['open', 'high', 'low', 'close']:\n",
    "        new_data[column] = data[column] / 10000.0\n",
    "\n",
    "    # new_data.dropna(inplace=True)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据转换"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 转换函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 阴阳线\n",
    "def stick_type(x):\n",
    "    stick_type = -1\n",
    "    if x['close'] >= x['open']:\n",
    "        stick_type = 1\n",
    "    return stick_type\n",
    "\n",
    "# 上引线\n",
    "def up_line(x):\n",
    "    return x['high'] - x[['open','close']].max()\n",
    "\n",
    "# 下引线\n",
    "def down_line(x):\n",
    "    return -(x[['open','close']].min() - x['low'])\n",
    "\n",
    "# 实体长度\n",
    "def body_size(x):\n",
    "    return x['close'] - x['open']\n",
    "\n",
    "def range_to_class(x):\n",
    "    cls = []\n",
    "    if x >= 0:\n",
    "        for i in range(num_classes):\n",
    "            if i == x:\n",
    "                cls.append(1.0)\n",
    "            else:\n",
    "                cls.append(0.0)\n",
    "    else:\n",
    "        print(x)\n",
    "        print(\"Error: n less than 0\")\n",
    "    return cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# std_ration = 0.5\n",
    "# def range_to_class(x):\n",
    "#     df = pd.DataFrame(index=x.index)\n",
    "#     df['close'] = x['close']\n",
    "#     df['next_close'] = df['close'].shift(-1)\n",
    "#     df['mean'] = df['close'].rolling(window=60, center=False, min_periods=60).mean()\n",
    "#     df['std'] = df['close'].rolling(window=60, center=False, min_periods=60).std()\n",
    "#     df.fillna(method='bfill', inplace=True)\n",
    "#     df['down'] = df['mean'] - std_ration * df['std']\n",
    "#     df['up'] = df['mean'] + std_ration * df['std']\n",
    "#     df['class'] = np.nan\n",
    "#     df.loc[df['next_close'] > df['up'], 'class'] = 2\n",
    "#     df.loc[df['next_close'] < df['down'], 'class'] = 0\n",
    "#     cond = (df['next_close'] <= df['up']) & (df['next_close'] >= df['down'])\n",
    "#     df.loc[cond, 'class'] = 1\n",
    "#     # last row has no next_close\n",
    "#     new_data.dropna(inplace=True)\n",
    "    \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_dim = 7\n",
    "data_dim = data_dim + new_dim\n",
    "std_ration = 0.5\n",
    "def data_transform(data):\n",
    "    new_data = pd.DataFrame()\n",
    "    pre_close = data['close'].shift(1)\n",
    "    for column in ['open', 'high', 'low', 'close']:\n",
    "        new_data[column] = (data[column] - pre_close) / pre_close\n",
    "        \n",
    "    # add new feature\n",
    "    new_data['stick_type'] = new_data.apply(stick_type, axis=1)\n",
    "    new_data['up_line'] = new_data.apply(up_line, axis=1)\n",
    "    new_data['down_line'] = new_data.apply(down_line, axis=1)\n",
    "    new_data['close_open'] = new_data.apply(body_size, axis=1)\n",
    "    \n",
    "    # macd\n",
    "    macd = MACD(data.astype({'close': \"double\"}), price='close')\n",
    "    new_data = pd.concat([new_data, macd], axis=1)\n",
    "    new_data.dropna(inplace=True)\n",
    "    \n",
    "    # new_data['class'] = new_data.apply(range_to_class, axis=1)\n",
    "    #new_data.dropna(inplace=True)\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    df['close'] = new_data['close']\n",
    "    df['next_close'] = df['close'].shift(-1)\n",
    "#     df['mean'] = df['close'].rolling(window=60, center=False, min_periods=60).mean()\n",
    "#     df['std'] = df['close'].rolling(window=60, center=False, min_periods=60).std()\n",
    "    df['mean'] = df['close'].mean()\n",
    "    df['std'] = df['close'].std()\n",
    "    \n",
    "    df.fillna(method='bfill', inplace=True)\n",
    "    df['down'] = df['mean'] - std_ration * df['std']\n",
    "    df['up'] = df['mean'] + std_ration * df['std']\n",
    "    df['class'] = np.nan\n",
    "    df.loc[df['next_close'] > df['up'], 'class'] = 2\n",
    "    df.loc[df['next_close'] < df['down'], 'class'] = 0\n",
    "    cond = (df['next_close'] <= df['up']) & (df['next_close'] >= df['down'])\n",
    "    df.loc[cond, 'class'] = 1\n",
    "    new_data['class'] = df['class']\n",
    "    # last row has no next_close\n",
    "    new_data.dropna(inplace=True)\n",
    "    \n",
    "    # new_data['class']= new_data['class'].map(range_to_class)\n",
    "        \n",
    "#     # classes\n",
    "#     new_data['class'] = new_data['close'].shift(-1)\n",
    "#     # new_data.dropna(inplace=True)\n",
    "#     new_data.fillna(0, inplace=True)\n",
    "#     new_data['class']= new_data['class'].map(range_to_class)\n",
    "        \n",
    "    # new_data.dropna(inplace=True)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_set(data, codes):\n",
    "    data_set = {}\n",
    "    for code in codes:\n",
    "        query_str = 'code=={0}'.format(code)\n",
    "        data_match = data.query(query_str)\n",
    "        data_cleaned = data_clean(data_match)\n",
    "        data_transformed = data_transform(data_cleaned)\n",
    "        print('code: {0}, data set len: {1}, start at: {2}, end at: {3}'.format(\n",
    "            code, len(data_transformed), data_transformed.index[0],data_transformed.index[-1]))\n",
    "        data_set[code] = data_transformed\n",
    "    return data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code: 990905, data set len: 2382, start at: (990905, Timestamp('2007-03-21 00:00:00')), end at: (990905, Timestamp('2016-12-29 00:00:00'))\n",
      "code: 399005, data set len: 2625, start at: (399005, Timestamp('2006-03-21 00:00:00')), end at: (399005, Timestamp('2016-12-29 00:00:00'))\n",
      "code: 399006, data set len: 1567, start at: (399006, Timestamp('2010-07-21 00:00:00')), end at: (399006, Timestamp('2016-12-29 00:00:00'))\n",
      "code: 999987, data set len: 3124, start at: (999987, Timestamp('2004-03-01 00:00:00')), end at: (999987, Timestamp('2016-12-29 00:00:00'))\n",
      "code: 300, data set len: 2814, start at: (300, Timestamp('2005-06-01 00:00:00')), end at: (300, Timestamp('2016-12-29 00:00:00'))\n"
     ]
    }
   ],
   "source": [
    "data_set = get_data_set(data_all, idxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>stick_type</th>\n",
       "      <th>up_line</th>\n",
       "      <th>down_line</th>\n",
       "      <th>close_open</th>\n",
       "      <th>macd</th>\n",
       "      <th>macdsignal</th>\n",
       "      <th>macdhist</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">990905</th>\n",
       "      <th>2007-03-21</th>\n",
       "      <td>0.003816</td>\n",
       "      <td>0.017191</td>\n",
       "      <td>-0.003127</td>\n",
       "      <td>0.017181</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>-0.006943</td>\n",
       "      <td>0.013365</td>\n",
       "      <td>153.861444</td>\n",
       "      <td>155.246046</td>\n",
       "      <td>-1.384602</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-03-22</th>\n",
       "      <td>0.003758</td>\n",
       "      <td>0.014110</td>\n",
       "      <td>-0.002216</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.010352</td>\n",
       "      <td>-0.002964</td>\n",
       "      <td>-0.003009</td>\n",
       "      <td>154.535245</td>\n",
       "      <td>155.103886</td>\n",
       "      <td>-0.568640</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-03-23</th>\n",
       "      <td>0.000518</td>\n",
       "      <td>0.014204</td>\n",
       "      <td>-0.014035</td>\n",
       "      <td>0.012881</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001323</td>\n",
       "      <td>-0.014553</td>\n",
       "      <td>0.012362</td>\n",
       "      <td>156.241908</td>\n",
       "      <td>155.331490</td>\n",
       "      <td>0.910418</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-03-26</th>\n",
       "      <td>0.005883</td>\n",
       "      <td>0.031419</td>\n",
       "      <td>0.005883</td>\n",
       "      <td>0.031419</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.025536</td>\n",
       "      <td>163.061909</td>\n",
       "      <td>156.877574</td>\n",
       "      <td>6.184335</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-03-27</th>\n",
       "      <td>0.002145</td>\n",
       "      <td>0.017162</td>\n",
       "      <td>-0.003320</td>\n",
       "      <td>0.016889</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>-0.005466</td>\n",
       "      <td>0.014744</td>\n",
       "      <td>170.574093</td>\n",
       "      <td>159.616878</td>\n",
       "      <td>10.957216</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       open      high       low     close  stick_type  \\\n",
       "code   date                                                             \n",
       "990905 2007-03-21  0.003816  0.017191 -0.003127  0.017181           1   \n",
       "       2007-03-22  0.003758  0.014110 -0.002216  0.000749          -1   \n",
       "       2007-03-23  0.000518  0.014204 -0.014035  0.012881           1   \n",
       "       2007-03-26  0.005883  0.031419  0.005883  0.031419           1   \n",
       "       2007-03-27  0.002145  0.017162 -0.003320  0.016889           1   \n",
       "\n",
       "                    up_line  down_line  close_open        macd  macdsignal  \\\n",
       "code   date                                                                  \n",
       "990905 2007-03-21  0.000009  -0.006943    0.013365  153.861444  155.246046   \n",
       "       2007-03-22  0.010352  -0.002964   -0.003009  154.535245  155.103886   \n",
       "       2007-03-23  0.001323  -0.014553    0.012362  156.241908  155.331490   \n",
       "       2007-03-26  0.000000  -0.000000    0.025536  163.061909  156.877574   \n",
       "       2007-03-27  0.000272  -0.005466    0.014744  170.574093  159.616878   \n",
       "\n",
       "                    macdhist  class  \n",
       "code   date                          \n",
       "990905 2007-03-21  -1.384602    1.0  \n",
       "       2007-03-22  -0.568640    2.0  \n",
       "       2007-03-23   0.910418    2.0  \n",
       "       2007-03-26   6.184335    2.0  \n",
       "       2007-03-27  10.957216    0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set[990905].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    new_data = data.copy()\n",
    "    for column in ['open', 'high', 'low', 'close', 'close_open', 'macd', 'macdsignal', 'macdhist']:\n",
    "        new_data[column] = preprocessing.scale(new_data[column])\n",
    "        \n",
    "    updown_line_values = new_data.loc[:,['up_line', 'down_line']].values\n",
    "    updown_line_values_norm = preprocessing.scale(updown_line_values.reshape((-1,1))).reshape((-1, 2))\n",
    "    updown_df = pd.DataFrame(index=new_data.index, columns=['up_line', 'down_line'], data=updown_line_values_norm)\n",
    "    new_data['up_line'] = updown_df['up_line']\n",
    "    new_data['down_line'] = updown_df['down_line']\n",
    "        \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_set_norm = {}\n",
    "for code in data_set:\n",
    "    data_set_norm[code] = normalize(data_set[code])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>stick_type</th>\n",
       "      <th>up_line</th>\n",
       "      <th>down_line</th>\n",
       "      <th>close_open</th>\n",
       "      <th>macd</th>\n",
       "      <th>macdsignal</th>\n",
       "      <th>macdhist</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">990905</th>\n",
       "      <th>2007-03-21</th>\n",
       "      <td>0.602567</td>\n",
       "      <td>0.488264</td>\n",
       "      <td>0.595657</td>\n",
       "      <td>0.766097</td>\n",
       "      <td>1</td>\n",
       "      <td>0.122132</td>\n",
       "      <td>-0.772651</td>\n",
       "      <td>0.575542</td>\n",
       "      <td>0.970548</td>\n",
       "      <td>1.041022</td>\n",
       "      <td>-0.022535</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-03-22</th>\n",
       "      <td>0.595456</td>\n",
       "      <td>0.250186</td>\n",
       "      <td>0.648900</td>\n",
       "      <td>0.008084</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.453296</td>\n",
       "      <td>-0.260574</td>\n",
       "      <td>-0.233408</td>\n",
       "      <td>0.975152</td>\n",
       "      <td>1.039987</td>\n",
       "      <td>-0.004502</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-03-23</th>\n",
       "      <td>0.201797</td>\n",
       "      <td>0.257447</td>\n",
       "      <td>-0.041743</td>\n",
       "      <td>0.567706</td>\n",
       "      <td>1</td>\n",
       "      <td>0.291246</td>\n",
       "      <td>-1.752101</td>\n",
       "      <td>0.525985</td>\n",
       "      <td>0.986812</td>\n",
       "      <td>1.041643</td>\n",
       "      <td>0.028186</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-03-26</th>\n",
       "      <td>0.853752</td>\n",
       "      <td>1.587776</td>\n",
       "      <td>1.122149</td>\n",
       "      <td>1.422842</td>\n",
       "      <td>1</td>\n",
       "      <td>0.120941</td>\n",
       "      <td>0.120941</td>\n",
       "      <td>1.176811</td>\n",
       "      <td>1.033410</td>\n",
       "      <td>1.052893</td>\n",
       "      <td>0.144743</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-03-27</th>\n",
       "      <td>0.399542</td>\n",
       "      <td>0.486022</td>\n",
       "      <td>0.584350</td>\n",
       "      <td>0.752623</td>\n",
       "      <td>1</td>\n",
       "      <td>0.155990</td>\n",
       "      <td>-0.582541</td>\n",
       "      <td>0.643646</td>\n",
       "      <td>1.084737</td>\n",
       "      <td>1.072826</td>\n",
       "      <td>0.250227</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       open      high       low     close  stick_type  \\\n",
       "code   date                                                             \n",
       "990905 2007-03-21  0.602567  0.488264  0.595657  0.766097           1   \n",
       "       2007-03-22  0.595456  0.250186  0.648900  0.008084          -1   \n",
       "       2007-03-23  0.201797  0.257447 -0.041743  0.567706           1   \n",
       "       2007-03-26  0.853752  1.587776  1.122149  1.422842           1   \n",
       "       2007-03-27  0.399542  0.486022  0.584350  0.752623           1   \n",
       "\n",
       "                    up_line  down_line  close_open      macd  macdsignal  \\\n",
       "code   date                                                                \n",
       "990905 2007-03-21  0.122132  -0.772651    0.575542  0.970548    1.041022   \n",
       "       2007-03-22  1.453296  -0.260574   -0.233408  0.975152    1.039987   \n",
       "       2007-03-23  0.291246  -1.752101    0.525985  0.986812    1.041643   \n",
       "       2007-03-26  0.120941   0.120941    1.176811  1.033410    1.052893   \n",
       "       2007-03-27  0.155990  -0.582541    0.643646  1.084737    1.072826   \n",
       "\n",
       "                   macdhist  class  \n",
       "code   date                         \n",
       "990905 2007-03-21 -0.022535    1.0  \n",
       "       2007-03-22 -0.004502    2.0  \n",
       "       2007-03-23  0.028186    2.0  \n",
       "       2007-03-26  0.144743    2.0  \n",
       "       2007-03-27  0.250227    0.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set_norm[990905].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(data, date, timesteps, batch_size):\n",
    "    min_num = int(batch_size) * int(timesteps)\n",
    "    \n",
    "    train_query_str = 'date <= \"{}\"'.format(date)\n",
    "    test_query_str = 'date > \"{}\"'.format(date)\n",
    "    \n",
    "    train = data.query(train_query_str)\n",
    "    test = data.query(test_query_str)\n",
    "    \n",
    "    train_size = len(train)\n",
    "    test_size = len(test)\n",
    "    print('split set to train size: {0}, test size: {1}'.format(train_size, test_size))\n",
    "    \n",
    "    train_batchs = int(train_size / min_num)\n",
    "    test_batchs = int(test_size / min_num)\n",
    "    \n",
    "    if train_batchs > 0:\n",
    "        train = train[-(train_batchs * min_num + 1):-1]\n",
    "    else:\n",
    "        train = None\n",
    "\n",
    "    if test_batchs > 0:\n",
    "        test = test[0:test_batchs * min_num]\n",
    "    else:\n",
    "        test = None\n",
    "    \n",
    "    print(\"train set len: {0}, start at {1}, end at {2}\".format(len(train), train.index[0], train.index[-1]))\n",
    "    print(\"test set len: {0}, start at {1}, end at {2}\".format(len(test), test.index[0], test.index[-1])) \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spliting code: 990905\n",
      "split set to train size: 2126, test size: 256\n",
      "train set len: 2048, start at (990905, Timestamp('2007-07-13 00:00:00')), end at (990905, Timestamp('2015-12-11 00:00:00'))\n",
      "test set len: 256, start at (990905, Timestamp('2015-12-15 00:00:00')), end at (990905, Timestamp('2016-12-29 00:00:00'))\n",
      "spliting code: 999987\n",
      "split set to train size: 2868, test size: 256\n",
      "train set len: 2816, start at (999987, Timestamp('2004-05-18 00:00:00')), end at (999987, Timestamp('2015-12-11 00:00:00'))\n",
      "test set len: 256, start at (999987, Timestamp('2015-12-15 00:00:00')), end at (999987, Timestamp('2016-12-29 00:00:00'))\n",
      "spliting code: 300\n",
      "split set to train size: 2558, test size: 256\n",
      "train set len: 2432, start at (300, Timestamp('2005-12-08 00:00:00')), end at (300, Timestamp('2015-12-11 00:00:00'))\n",
      "test set len: 256, start at (300, Timestamp('2015-12-15 00:00:00')), end at (300, Timestamp('2016-12-29 00:00:00'))\n",
      "spliting code: 399005\n",
      "split set to train size: 2369, test size: 256\n",
      "train set len: 2304, start at (399005, Timestamp('2006-06-26 00:00:00')), end at (399005, Timestamp('2015-12-11 00:00:00'))\n",
      "test set len: 256, start at (399005, Timestamp('2015-12-15 00:00:00')), end at (399005, Timestamp('2016-12-29 00:00:00'))\n",
      "spliting code: 399006\n",
      "split set to train size: 1311, test size: 256\n",
      "train set len: 1280, start at (399006, Timestamp('2010-09-01 00:00:00')), end at (399006, Timestamp('2015-12-11 00:00:00'))\n",
      "test set len: 256, start at (399006, Timestamp('2015-12-15 00:00:00')), end at (399006, Timestamp('2016-12-29 00:00:00'))\n"
     ]
    }
   ],
   "source": [
    "df_train_set = {}\n",
    "df_test_set = {}\n",
    "\n",
    "for code in data_set_norm:\n",
    "    print('spliting code: {0}'.format(code))\n",
    "    train, test = split_data(data_set_norm[code], '20151214', timesteps=timesteps, batch_size=batch_size)\n",
    "    df_train_set[code] = train\n",
    "    df_test_set[code] = test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据重整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_reform(data, batch_size, timesteps):\n",
    "    data['class']= data['class'].map(range_to_class)\n",
    "    data_values = data.values\n",
    "    \n",
    "    print(\"shape: {0}\".format(data_values.shape))\n",
    "    size = len(data_values)\n",
    "    if size % (int(batch_size) * int(timesteps)) != 0:\n",
    "        print(\"data size not match, size: {0}, batch_size: {1}, timesteps: {2}\".format(size, batch_size, timesteps))\n",
    "        return None, None\n",
    "   \n",
    "    X, Y0 = data_values[:, :-1], data_values[:, -1]\n",
    "    \n",
    "    X = X.reshape((-1, timesteps, X.shape[1]))\n",
    "    \n",
    "    Y = np.array([np.array(y) for y in Y0])\n",
    "       \n",
    "    Y = Y.reshape((-1, timesteps, Y.shape[1]))\n",
    "    \n",
    "    print(\"X.shape: {0} Y.shape: {1}\".format(X.shape, Y.shape))\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2048, 12)\n",
      "X.shape: (64, 32, 11) Y.shape: (64, 32, 3)\n",
      "shape: (2816, 12)\n",
      "X.shape: (88, 32, 11) Y.shape: (88, 32, 3)\n",
      "shape: (2432, 12)\n",
      "X.shape: (76, 32, 11) Y.shape: (76, 32, 3)\n",
      "shape: (2304, 12)\n",
      "X.shape: (72, 32, 11) Y.shape: (72, 32, 3)\n",
      "shape: (1280, 12)\n",
      "X.shape: (40, 32, 11) Y.shape: (40, 32, 3)\n",
      "shape: (256, 12)\n",
      "X.shape: (8, 32, 11) Y.shape: (8, 32, 3)\n",
      "shape: (256, 12)\n",
      "X.shape: (8, 32, 11) Y.shape: (8, 32, 3)\n",
      "shape: (256, 12)\n",
      "X.shape: (8, 32, 11) Y.shape: (8, 32, 3)\n",
      "shape: (256, 12)\n",
      "X.shape: (8, 32, 11) Y.shape: (8, 32, 3)\n",
      "shape: (256, 12)\n",
      "X.shape: (8, 32, 11) Y.shape: (8, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "train_set = {}\n",
    "test_set = {}\n",
    "\n",
    "for code in df_train_set:\n",
    "    train_set[code] = data_reform(df_train_set[code], batch_size, timesteps)\n",
    "                                  \n",
    "for code in df_test_set:\n",
    "    test_set[code] = data_reform(df_test_set[code], batch_size, timesteps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_all = data_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx_dict = {'上证50': 999987, '沪深300': 300, '中证500': 990905, '中小板指': 399005, '创业板指': 399006}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 确认指数代码\n",
    "for idx_name in idx_dict:\n",
    "    print(\"name: {0}\".format(idx_name))\n",
    "    Id = data_all[data_all['name'] == idx_name].index.get_level_values('code').unique()\n",
    "    print(\"Id: {0}\".format(Id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "years = pd.date_range('1/1/2006', periods=11, freq='A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_stat(data, years, idx_dict):\n",
    "    idxes_des = pd.DataFrame()\n",
    "    for name in idx_dict:\n",
    "        # print(name)\n",
    "        code = idx_dict[name]\n",
    "        query_code = 'code=={0}'.format(code)\n",
    "        # print(\"query code: {0}\".format(query_code))\n",
    "        data_code = data.query(query_code)\n",
    "        data_code_c = data_clean(data_code)\n",
    "        data_code_t = data_transform(data_code_c)\n",
    "        idx_des = pd.DataFrame()\n",
    "        for year in years:\n",
    "            end_date = year\n",
    "            begin_date  = year.replace(month=1, day=1)\n",
    "            query_date = 'date>\"{0}\" & date < \"{1}\"'.format(begin_date, end_date)\n",
    "            # print(\"query date: {0}\".format(query_date))\n",
    "            data_code_year = data_code_t.query(query_date)\n",
    "            describe = data_code_year.close.describe()\n",
    "            df_describe = describe.to_frame().reset_index()\n",
    "            df_describe['date'] = year\n",
    "            idx_des = pd.concat([idx_des, df_describe])\n",
    "        idx_des = idx_des.pivot(index='date', columns='index', values='close')    \n",
    "        idx_des['code'] = code\n",
    "        idxes_des = pd.concat([idxes_des, idx_des])\n",
    "    return idxes_des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_stat = data_stat(data_all, years, idx_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_stat_d = data_stat.drop(['count', 'min', 'max', 'std'],axis=1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = data_stat_d.reset_index().set_index(['code', 'date'])\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(8, 6))\n",
    "t.loc[999987].plot(ax=axes[0, 0])\n",
    "t.loc[300].plot(ax=axes[0, 1])\n",
    "t.loc[990905].plot(ax=axes[1, 0])\n",
    "t.loc[399005].plot(ax=axes[1, 1])\n",
    "t.loc[399006].plot(ax=axes[2, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 32, 11)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size, timesteps, data_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_17 (LSTM)               (4, 32, 32)               5632      \n",
      "_________________________________________________________________\n",
      "lstm_18 (LSTM)               (4, 32, 32)               8320      \n",
      "_________________________________________________________________\n",
      "lstm_19 (LSTM)               (4, 32, 32)               8320      \n",
      "_________________________________________________________________\n",
      "lstm_20 (LSTM)               (4, 32, 32)               8320      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (4, 32, 3)                99        \n",
      "=================================================================\n",
      "Total params: 30,691\n",
      "Trainable params: 30,691\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.layers import LSTM, Dense, Dropout, BatchNormalization, Activation\n",
    "\n",
    "units\n",
    "model = Sequential()\n",
    "# input layer\n",
    "# activation='relu' \n",
    "# dropout=0.5\n",
    "# kernel_initializer=\"uniform\"\n",
    "model.add(LSTM(units, stateful=True, return_sequences=True, batch_input_shape=(batch_size, timesteps, data_dim), activation='relu'))\n",
    "# hidden layer\n",
    "model.add(LSTM(units, return_sequences=True, stateful=True, dropout=0.5))\n",
    "model.add(LSTM(units, return_sequences=True, stateful=True, dropout=0.5))\n",
    "model.add(LSTM(units, return_sequences=True, stateful=True, dropout=0.5))\n",
    "\n",
    "# 回归问题\n",
    "# # output layer\n",
    "# # model.add(Dense(no_classes, activation='softmax'))\n",
    "# model.add(Dense(1, activation='sigmoid')) # or sigmoid?\n",
    "# # model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# model.compile(optimizer='RMSProp', loss='mse') #mse\n",
    "\n",
    "# 分类问题\n",
    "# output layer\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "# model.add(Dense(num_classes, kernel_initializer=\"uniform\"))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation('softmax'))\n",
    "\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "model.compile(optimizer=RMSprop(0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_set(data, codes):\n",
    "    data_set = {}\n",
    "    for code in codes:\n",
    "        query_str = 'code=={0}'.format(code)\n",
    "        data_match = data.query(query_str)\n",
    "        data_cleaned = data_clean(data_match)\n",
    "        data_transformed = data_transform(data_cleaned)\n",
    "        print(data_transformed.index[0])\n",
    "        print(data_transformed.index[-1])\n",
    "        data_set[code] = data_transformed\n",
    "    return data_set\n",
    "\n",
    "data_set = get_data_set(data_all, ['990905', '999987'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_set['990905'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = range_to_class(data_set['990905'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df['class'].plot.hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_set_norm = normalize(data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_set['990905'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_set_norm['990905'].low.plot.hist(bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_set_norm['990905']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zz500_close = data_set['990905']['close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean = zz500_close.rolling(window=60, center=False, min_periods=60).mean()\n",
    "std = zz500_close.rolling(window=60, center=False, min_periods=60).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(zz500_close.head(70).tail(10))\n",
    "print(mean.head(70).tail(10))\n",
    "print(std.head(70).tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xxx['990905'].down_line.plot.hist(bins=30)\n",
    "xxx['990905'].up_line.plot.hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datx['990905'].down_line.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query_str = 'code=={0}'.format(300)\n",
    "hs300 = data_all.query(query_str)\n",
    "hs300_close = hs300['close'] / 10000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hs300_close.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean = hs300_close.rolling(window=60, center=False, min_periods=60).mean()\n",
    "std = hs300_close.rolling(window=60, center=False, min_periods=60).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "std.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hs300_close.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_codes = ['990905', '999987']\n",
    "test_date_query = 'date>\"20141120\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_test_set = get_data_set(data_all, test_codes, test_date_query, timesteps, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#raw_test_set['999987'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_set = {}\n",
    "for code in raw_test_set:\n",
    "    test_set[code] = data_reform(normalize(raw_test_set[code]).values, batch_size, timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idxes = data_all.index.get_level_values('code').unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_map = {'上证50': 999987, '沪深300': 300, '中证500': 990905, '中小板指': 399005, '创业板指': 399006}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train sets\n",
    "train_codes = []\n",
    "for key in train_map:\n",
    "    train_codes.append(train_map[key])\n",
    "    \n",
    "train_date_query = 'date<\"20150101\"'\n",
    "\n",
    "raw_train_set = get_data_set(data_all, train_codes, train_date_query, timesteps, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_train_set[300].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = {}\n",
    "for code in raw_train_set:\n",
    "    train_set[code] = data_reform(normalize(raw_train_set[code]).values, batch_size, timesteps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from influxdb import InfluxDBClient\n",
    "from influxdb import SeriesHelper\n",
    "host = '183.136.205.102'\n",
    "port = 38086\n",
    "user = 'root'\n",
    "password = 'root'\n",
    "dbname = 'chq'\n",
    "\n",
    "myclient = InfluxDBClient(host, port, user, password, dbname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainid = 5\n",
    "class MySeriesHelper(SeriesHelper):\n",
    "    # Meta class stores time series helper configuration.\n",
    "    class Meta:\n",
    "        # The client should be an instance of InfluxDBClient.\n",
    "        client = myclient\n",
    "        # The series name must be a string. Add dependent fields/tags in curly brackets.\n",
    "        series_name = 'deeplearning.train' + str(trainid)\n",
    "        # Defines all the fields in this time series.\n",
    "        fields = ['loss', 'acc']\n",
    "        # Defines all the tags for the series.\n",
    "        tags = ['dtype', 'code', 'epoch']\n",
    "        # Defines the number of data points to store prior to writing on the wire.\n",
    "        bulk_size = 5\n",
    "        # autocommit must be set to True when using bulk_size\n",
    "        autocommit = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs =2000\n",
    "def train(model, train_set, test_set, epochs, batch_size):\n",
    "# def train():\n",
    "    for e in range(epochs):\n",
    "        for code in train_set:\n",
    "            print(\"epochs: {0}, code: {1}\".format(e, code))\n",
    "            train_X, train_Y = train_set[code]\n",
    "            # print(train_X.shape, train_Y.shape, test_X.shape, test_Y.shape)\n",
    "            # history = model.fit(train_X, train_Y, epochs=100, batch_size=batch_size, validation_data=(test_X, test_Y), verbose=1, shuffle=False)\n",
    "            history = model.fit(train_X, train_Y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n",
    "            model.reset_states()  \n",
    "            # result = {'type': 'train', 'code': code, 'train_loss': (e, history.history['loss'][-1]), 'train_acc': (e, history.history['acc'][-1])}\n",
    "            MySeriesHelper(dtype=\"train\", code=code, epoch = e, loss=history.history['loss'][-1], acc= history.history['acc'][-1])\n",
    "            # print(result)\n",
    "        MySeriesHelper.commit()\n",
    "            # yield result\n",
    "        for code in test_set:\n",
    "            test_X1, test_Y1 = test_set[code]\n",
    "            loss_and_metrics = model.evaluate(test_X1, test_Y1, batch_size=batch_size)\n",
    "            model.reset_states()\n",
    "            # result = {'type': 'test', 'code': code, 'test_loss': (e, loss_and_metrics[0]), 'test_acc': (e, loss_and_metrics[1])}\n",
    "            MySeriesHelper(dtype=\"test\", code=code, epoch = e, loss=loss_and_metrics[0], acc= loss_and_metrics[1])\n",
    "            # print(result)\n",
    "        MySeriesHelper.commit()\n",
    "            # yield result\n",
    "                # print(\"==================================\")\n",
    "                # print(\"loss_and_metrics: {0}\".format(loss_and_metrics))\n",
    "                # print(\"==================================\")\n",
    "\n",
    "#     def data_gen(t=0):\n",
    "#         cnt = 0\n",
    "#         while cnt < 1000:\n",
    "#             cnt += 1\n",
    "#             t += 0.1\n",
    "#             yield t, np.sin(2*np.pi*t) * np.exp(-t/10.)\n",
    "# ani = animation.FuncAnimation(fig, run, train, repeat=False, init_func=init)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 0, code: 990905\n",
      "epochs: 0, code: 999987\n",
      "epochs: 0, code: 300\n",
      "epochs: 0, code: 399005\n",
      "epochs: 0, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 1, code: 990905\n",
      "epochs: 1, code: 999987\n",
      "epochs: 1, code: 300\n",
      "epochs: 1, code: 399005\n",
      "epochs: 1, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 2, code: 990905\n",
      "epochs: 2, code: 999987\n",
      "epochs: 2, code: 300\n",
      "epochs: 2, code: 399005\n",
      "epochs: 2, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 3, code: 990905\n",
      "epochs: 3, code: 999987\n",
      "epochs: 3, code: 300\n",
      "epochs: 3, code: 399005\n",
      "epochs: 3, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 4, code: 990905\n",
      "epochs: 4, code: 999987\n",
      "epochs: 4, code: 300\n",
      "epochs: 4, code: 399005\n",
      "epochs: 4, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 5, code: 990905\n",
      "epochs: 5, code: 999987\n",
      "epochs: 5, code: 300\n",
      "epochs: 5, code: 399005\n",
      "epochs: 5, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 6, code: 990905\n",
      "epochs: 6, code: 999987\n",
      "epochs: 6, code: 300\n",
      "epochs: 6, code: 399005\n",
      "epochs: 6, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 7, code: 990905\n",
      "epochs: 7, code: 999987\n",
      "epochs: 7, code: 300\n",
      "epochs: 7, code: 399005\n",
      "epochs: 7, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 8, code: 990905\n",
      "epochs: 8, code: 999987\n",
      "epochs: 8, code: 300\n",
      "epochs: 8, code: 399005\n",
      "epochs: 8, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 9, code: 990905\n",
      "epochs: 9, code: 999987\n",
      "epochs: 9, code: 300\n",
      "epochs: 9, code: 399005\n",
      "epochs: 9, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 10, code: 990905\n",
      "epochs: 10, code: 999987\n",
      "epochs: 10, code: 300\n",
      "epochs: 10, code: 399005\n",
      "epochs: 10, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 11, code: 990905\n",
      "epochs: 11, code: 999987\n",
      "epochs: 11, code: 300\n",
      "epochs: 11, code: 399005\n",
      "epochs: 11, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 12, code: 990905\n",
      "epochs: 12, code: 999987\n",
      "epochs: 12, code: 300\n",
      "epochs: 12, code: 399005\n",
      "epochs: 12, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 13, code: 990905\n",
      "epochs: 13, code: 999987\n",
      "epochs: 13, code: 300\n",
      "epochs: 13, code: 399005\n",
      "epochs: 13, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 14, code: 990905\n",
      "epochs: 14, code: 999987\n",
      "epochs: 14, code: 300\n",
      "epochs: 14, code: 399005\n",
      "epochs: 14, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 15, code: 990905\n",
      "epochs: 15, code: 999987\n",
      "epochs: 15, code: 300\n",
      "epochs: 15, code: 399005\n",
      "epochs: 15, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 16, code: 990905\n",
      "epochs: 16, code: 999987\n",
      "epochs: 16, code: 300\n",
      "epochs: 16, code: 399005\n",
      "epochs: 16, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 17, code: 990905\n",
      "epochs: 17, code: 999987\n",
      "epochs: 17, code: 300\n",
      "epochs: 17, code: 399005\n",
      "epochs: 17, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 18, code: 990905\n",
      "epochs: 18, code: 999987\n",
      "epochs: 18, code: 300\n",
      "epochs: 18, code: 399005\n",
      "epochs: 18, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 19, code: 990905\n",
      "epochs: 19, code: 999987\n",
      "epochs: 19, code: 300\n",
      "epochs: 19, code: 399005\n",
      "epochs: 19, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 20, code: 990905\n",
      "epochs: 20, code: 999987\n",
      "epochs: 20, code: 300\n",
      "epochs: 20, code: 399005\n",
      "epochs: 20, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 21, code: 990905\n",
      "epochs: 21, code: 999987\n",
      "epochs: 21, code: 300\n",
      "epochs: 21, code: 399005\n",
      "epochs: 21, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 22, code: 990905\n",
      "epochs: 22, code: 999987\n",
      "epochs: 22, code: 300\n",
      "epochs: 22, code: 399005\n",
      "epochs: 22, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 23, code: 990905\n",
      "epochs: 23, code: 999987\n",
      "epochs: 23, code: 300\n",
      "epochs: 23, code: 399005\n",
      "epochs: 23, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 24, code: 990905\n",
      "epochs: 24, code: 999987\n",
      "epochs: 24, code: 300\n",
      "epochs: 24, code: 399005\n",
      "epochs: 24, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 25, code: 990905\n",
      "epochs: 25, code: 999987\n",
      "epochs: 25, code: 300\n",
      "epochs: 25, code: 399005\n",
      "epochs: 25, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 26, code: 990905\n",
      "epochs: 26, code: 999987\n",
      "epochs: 26, code: 300\n",
      "epochs: 26, code: 399005\n",
      "epochs: 26, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 27, code: 990905\n",
      "epochs: 27, code: 999987\n",
      "epochs: 27, code: 300\n",
      "epochs: 27, code: 399005\n",
      "epochs: 27, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 28, code: 990905\n",
      "epochs: 28, code: 999987\n",
      "epochs: 28, code: 300\n",
      "epochs: 28, code: 399005\n",
      "epochs: 28, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 29, code: 990905\n",
      "epochs: 29, code: 999987\n",
      "epochs: 29, code: 300\n",
      "epochs: 29, code: 399005\n",
      "epochs: 29, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 30, code: 990905\n",
      "epochs: 30, code: 999987\n",
      "epochs: 30, code: 300\n",
      "epochs: 30, code: 399005\n",
      "epochs: 30, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 31, code: 990905\n",
      "epochs: 31, code: 999987\n",
      "epochs: 31, code: 300\n",
      "epochs: 31, code: 399005\n",
      "epochs: 31, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 32, code: 990905\n",
      "epochs: 32, code: 999987\n",
      "epochs: 32, code: 300\n",
      "epochs: 32, code: 399005\n",
      "epochs: 32, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 33, code: 990905\n",
      "epochs: 33, code: 999987\n",
      "epochs: 33, code: 300\n",
      "epochs: 33, code: 399005\n",
      "epochs: 33, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 34, code: 990905\n",
      "epochs: 34, code: 999987\n",
      "epochs: 34, code: 300\n",
      "epochs: 34, code: 399005\n",
      "epochs: 34, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 35, code: 990905\n",
      "epochs: 35, code: 999987\n",
      "epochs: 35, code: 300\n",
      "epochs: 35, code: 399005\n",
      "epochs: 35, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 36, code: 990905\n",
      "epochs: 36, code: 999987\n",
      "epochs: 36, code: 300\n",
      "epochs: 36, code: 399005\n",
      "epochs: 36, code: 399006\n",
      "8/8 [==============================] - 0s     \n",
      "4/8 [==============>...............] - ETA: 0sepochs: 37, code: 990905\n",
      "epochs: 37, code: 999987\n",
      "epochs: 37, code: 300\n",
      "epochs: 37, code: 399005\n",
      "epochs: 37, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 38, code: 990905\n",
      "epochs: 38, code: 999987\n",
      "epochs: 38, code: 300\n",
      "epochs: 38, code: 399005\n",
      "epochs: 38, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 39, code: 990905\n",
      "epochs: 39, code: 999987\n",
      "epochs: 39, code: 300\n",
      "epochs: 39, code: 399005\n",
      "epochs: 39, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 40, code: 990905\n",
      "epochs: 40, code: 999987\n",
      "epochs: 40, code: 300\n",
      "epochs: 40, code: 399005\n",
      "epochs: 40, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 41, code: 990905\n",
      "epochs: 41, code: 999987\n",
      "epochs: 41, code: 300\n",
      "epochs: 41, code: 399005\n",
      "epochs: 41, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 42, code: 990905\n",
      "epochs: 42, code: 999987\n",
      "epochs: 42, code: 300\n",
      "epochs: 42, code: 399005\n",
      "epochs: 42, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 43, code: 990905\n",
      "epochs: 43, code: 999987\n",
      "epochs: 43, code: 300\n",
      "epochs: 43, code: 399005\n",
      "epochs: 43, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 44, code: 990905\n",
      "epochs: 44, code: 999987\n",
      "epochs: 44, code: 300\n",
      "epochs: 44, code: 399005\n",
      "epochs: 44, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 45, code: 990905\n",
      "epochs: 45, code: 999987\n",
      "epochs: 45, code: 300\n",
      "epochs: 45, code: 399005\n",
      "epochs: 45, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 46, code: 990905\n",
      "epochs: 46, code: 999987\n",
      "epochs: 46, code: 300\n",
      "epochs: 46, code: 399005\n",
      "epochs: 46, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 47, code: 990905\n",
      "epochs: 47, code: 999987\n",
      "epochs: 47, code: 300\n",
      "epochs: 47, code: 399005\n",
      "epochs: 47, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 48, code: 990905\n",
      "epochs: 48, code: 999987\n",
      "epochs: 48, code: 300\n",
      "epochs: 48, code: 399005\n",
      "epochs: 48, code: 399006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/8 [==============>...............] - ETA: 0sepochs: 49, code: 990905\n",
      "epochs: 49, code: 999987\n",
      "epochs: 49, code: 300\n",
      "epochs: 49, code: 399005\n",
      "epochs: 49, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 50, code: 990905\n",
      "epochs: 50, code: 999987\n",
      "epochs: 50, code: 300\n",
      "epochs: 50, code: 399005\n",
      "epochs: 50, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 51, code: 990905\n",
      "epochs: 51, code: 999987\n",
      "epochs: 51, code: 300\n",
      "epochs: 51, code: 399005\n",
      "epochs: 51, code: 399006\n",
      "8/8 [==============================] - 0s     \n",
      "4/8 [==============>...............] - ETA: 0sepochs: 52, code: 990905\n",
      "epochs: 52, code: 999987\n",
      "epochs: 52, code: 300\n",
      "epochs: 52, code: 399005\n",
      "epochs: 52, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 53, code: 990905\n",
      "epochs: 53, code: 999987\n",
      "epochs: 53, code: 300\n",
      "epochs: 53, code: 399005\n",
      "epochs: 53, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 54, code: 990905\n",
      "epochs: 54, code: 999987\n",
      "epochs: 54, code: 300\n",
      "epochs: 54, code: 399005\n",
      "epochs: 54, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 55, code: 990905\n",
      "epochs: 55, code: 999987\n",
      "epochs: 55, code: 300\n",
      "epochs: 55, code: 399005\n",
      "epochs: 55, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 56, code: 990905\n",
      "epochs: 56, code: 999987\n",
      "epochs: 56, code: 300\n",
      "epochs: 56, code: 399005\n",
      "epochs: 56, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 57, code: 990905\n",
      "epochs: 57, code: 999987\n",
      "epochs: 57, code: 300\n",
      "epochs: 57, code: 399005\n",
      "epochs: 57, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 58, code: 990905\n",
      "epochs: 58, code: 999987\n",
      "epochs: 58, code: 300\n",
      "epochs: 58, code: 399005\n",
      "epochs: 58, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 59, code: 990905\n",
      "epochs: 59, code: 999987\n",
      "epochs: 59, code: 300\n",
      "epochs: 59, code: 399005\n",
      "epochs: 59, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 60, code: 990905\n",
      "epochs: 60, code: 999987\n",
      "epochs: 60, code: 300\n",
      "epochs: 60, code: 399005\n",
      "epochs: 60, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 61, code: 990905\n",
      "epochs: 61, code: 999987\n",
      "epochs: 61, code: 300\n",
      "epochs: 61, code: 399005\n",
      "epochs: 61, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 62, code: 990905\n",
      "epochs: 62, code: 999987\n",
      "epochs: 62, code: 300\n",
      "epochs: 62, code: 399005\n",
      "epochs: 62, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 63, code: 990905\n",
      "epochs: 63, code: 999987\n",
      "epochs: 63, code: 300\n",
      "epochs: 63, code: 399005\n",
      "epochs: 63, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 64, code: 990905\n",
      "epochs: 64, code: 999987\n",
      "epochs: 64, code: 300\n",
      "epochs: 64, code: 399005\n",
      "epochs: 64, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 65, code: 990905\n",
      "epochs: 65, code: 999987\n",
      "epochs: 65, code: 300\n",
      "epochs: 65, code: 399005\n",
      "epochs: 65, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 66, code: 990905\n",
      "epochs: 66, code: 999987\n",
      "epochs: 66, code: 300\n",
      "epochs: 66, code: 399005\n",
      "epochs: 66, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 67, code: 990905\n",
      "epochs: 67, code: 999987\n",
      "epochs: 67, code: 300\n",
      "epochs: 67, code: 399005\n",
      "epochs: 67, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 68, code: 990905\n",
      "epochs: 68, code: 999987\n",
      "epochs: 68, code: 300\n",
      "epochs: 68, code: 399005\n",
      "epochs: 68, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 69, code: 990905\n",
      "epochs: 69, code: 999987\n",
      "epochs: 69, code: 300\n",
      "epochs: 69, code: 399005\n",
      "epochs: 69, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 70, code: 990905\n",
      "epochs: 70, code: 999987\n",
      "epochs: 70, code: 300\n",
      "epochs: 70, code: 399005\n",
      "epochs: 70, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 71, code: 990905\n",
      "epochs: 71, code: 999987\n",
      "epochs: 71, code: 300\n",
      "epochs: 71, code: 399005\n",
      "epochs: 71, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 72, code: 990905\n",
      "epochs: 72, code: 999987\n",
      "epochs: 72, code: 300\n",
      "epochs: 72, code: 399005\n",
      "epochs: 72, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 73, code: 990905\n",
      "epochs: 73, code: 999987\n",
      "epochs: 73, code: 300\n",
      "epochs: 73, code: 399005\n",
      "epochs: 73, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 74, code: 990905\n",
      "epochs: 74, code: 999987\n",
      "epochs: 74, code: 300\n",
      "epochs: 74, code: 399005\n",
      "epochs: 74, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 75, code: 990905\n",
      "epochs: 75, code: 999987\n",
      "epochs: 75, code: 300\n",
      "epochs: 75, code: 399005\n",
      "epochs: 75, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 76, code: 990905\n",
      "epochs: 76, code: 999987\n",
      "epochs: 76, code: 300\n",
      "epochs: 76, code: 399005\n",
      "epochs: 76, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 77, code: 990905\n",
      "epochs: 77, code: 999987\n",
      "epochs: 77, code: 300\n",
      "epochs: 77, code: 399005\n",
      "epochs: 77, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 78, code: 990905\n",
      "epochs: 78, code: 999987\n",
      "epochs: 78, code: 300\n",
      "epochs: 78, code: 399005\n",
      "epochs: 78, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 79, code: 990905\n",
      "epochs: 79, code: 999987\n",
      "epochs: 79, code: 300\n",
      "epochs: 79, code: 399005\n",
      "epochs: 79, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 80, code: 990905\n",
      "epochs: 80, code: 999987\n",
      "epochs: 80, code: 300\n",
      "epochs: 80, code: 399005\n",
      "epochs: 80, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 81, code: 990905\n",
      "epochs: 81, code: 999987\n",
      "epochs: 81, code: 300\n",
      "epochs: 81, code: 399005\n",
      "epochs: 81, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 82, code: 990905\n",
      "epochs: 82, code: 999987\n",
      "epochs: 82, code: 300\n",
      "epochs: 82, code: 399005\n",
      "epochs: 82, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 83, code: 990905\n",
      "epochs: 83, code: 999987\n",
      "epochs: 83, code: 300\n",
      "epochs: 83, code: 399005\n",
      "epochs: 83, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 84, code: 990905\n",
      "epochs: 84, code: 999987\n",
      "epochs: 84, code: 300\n",
      "epochs: 84, code: 399005\n",
      "epochs: 84, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 85, code: 990905\n",
      "epochs: 85, code: 999987\n",
      "epochs: 85, code: 300\n",
      "epochs: 85, code: 399005\n",
      "epochs: 85, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 86, code: 990905\n",
      "epochs: 86, code: 999987\n",
      "epochs: 86, code: 300\n",
      "epochs: 86, code: 399005\n",
      "epochs: 86, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 87, code: 990905\n",
      "epochs: 87, code: 999987\n",
      "epochs: 87, code: 300\n",
      "epochs: 87, code: 399005\n",
      "epochs: 87, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 88, code: 990905\n",
      "epochs: 88, code: 999987\n",
      "epochs: 88, code: 300\n",
      "epochs: 88, code: 399005\n",
      "epochs: 88, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 89, code: 990905\n",
      "epochs: 89, code: 999987\n",
      "epochs: 89, code: 300\n",
      "epochs: 89, code: 399005\n",
      "epochs: 89, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 90, code: 990905\n",
      "epochs: 90, code: 999987\n",
      "epochs: 90, code: 300\n",
      "epochs: 90, code: 399005\n",
      "epochs: 90, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 91, code: 990905\n",
      "epochs: 91, code: 999987\n",
      "epochs: 91, code: 300\n",
      "epochs: 91, code: 399005\n",
      "epochs: 91, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 92, code: 990905\n",
      "epochs: 92, code: 999987\n",
      "epochs: 92, code: 300\n",
      "epochs: 92, code: 399005\n",
      "epochs: 92, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 93, code: 990905\n",
      "epochs: 93, code: 999987\n",
      "epochs: 93, code: 300\n",
      "epochs: 93, code: 399005\n",
      "epochs: 93, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 94, code: 990905\n",
      "epochs: 94, code: 999987\n",
      "epochs: 94, code: 300\n",
      "epochs: 94, code: 399005\n",
      "epochs: 94, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 95, code: 990905\n",
      "epochs: 95, code: 999987\n",
      "epochs: 95, code: 300\n",
      "epochs: 95, code: 399005\n",
      "epochs: 95, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 96, code: 990905\n",
      "epochs: 96, code: 999987\n",
      "epochs: 96, code: 300\n",
      "epochs: 96, code: 399005\n",
      "epochs: 96, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 97, code: 990905\n",
      "epochs: 97, code: 999987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 97, code: 300\n",
      "epochs: 97, code: 399005\n",
      "epochs: 97, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 98, code: 990905\n",
      "epochs: 98, code: 999987\n",
      "epochs: 98, code: 300\n",
      "epochs: 98, code: 399005\n",
      "epochs: 98, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 99, code: 990905\n",
      "epochs: 99, code: 999987\n",
      "epochs: 99, code: 300\n",
      "epochs: 99, code: 399005\n",
      "epochs: 99, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 100, code: 990905\n",
      "epochs: 100, code: 999987\n",
      "epochs: 100, code: 300\n",
      "epochs: 100, code: 399005\n",
      "epochs: 100, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 101, code: 990905\n",
      "epochs: 101, code: 999987\n",
      "epochs: 101, code: 300\n",
      "epochs: 101, code: 399005\n",
      "epochs: 101, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 102, code: 990905\n",
      "epochs: 102, code: 999987\n",
      "epochs: 102, code: 300\n",
      "epochs: 102, code: 399005\n",
      "epochs: 102, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 103, code: 990905\n",
      "epochs: 103, code: 999987\n",
      "epochs: 103, code: 300\n",
      "epochs: 103, code: 399005\n",
      "epochs: 103, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 104, code: 990905\n",
      "epochs: 104, code: 999987\n",
      "epochs: 104, code: 300\n",
      "epochs: 104, code: 399005\n",
      "epochs: 104, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 105, code: 990905\n",
      "epochs: 105, code: 999987\n",
      "epochs: 105, code: 300\n",
      "epochs: 105, code: 399005\n",
      "epochs: 105, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 106, code: 990905\n",
      "epochs: 106, code: 999987\n",
      "epochs: 106, code: 300\n",
      "epochs: 106, code: 399005\n",
      "epochs: 106, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 107, code: 990905\n",
      "epochs: 107, code: 999987\n",
      "epochs: 107, code: 300\n",
      "epochs: 107, code: 399005\n",
      "epochs: 107, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 108, code: 990905\n",
      "epochs: 108, code: 999987\n",
      "epochs: 108, code: 300\n",
      "epochs: 108, code: 399005\n",
      "epochs: 108, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 109, code: 990905\n",
      "epochs: 109, code: 999987\n",
      "epochs: 109, code: 300\n",
      "epochs: 109, code: 399005\n",
      "epochs: 109, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 110, code: 990905\n",
      "epochs: 110, code: 999987\n",
      "epochs: 110, code: 300\n",
      "epochs: 110, code: 399005\n",
      "epochs: 110, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 111, code: 990905\n",
      "epochs: 111, code: 999987\n",
      "epochs: 111, code: 300\n",
      "epochs: 111, code: 399005\n",
      "epochs: 111, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 112, code: 990905\n",
      "epochs: 112, code: 999987\n",
      "epochs: 112, code: 300\n",
      "epochs: 112, code: 399005\n",
      "epochs: 112, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 113, code: 990905\n",
      "epochs: 113, code: 999987\n",
      "epochs: 113, code: 300\n",
      "epochs: 113, code: 399005\n",
      "epochs: 113, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 114, code: 990905\n",
      "epochs: 114, code: 999987\n",
      "epochs: 114, code: 300\n",
      "epochs: 114, code: 399005\n",
      "epochs: 114, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 115, code: 990905\n",
      "epochs: 115, code: 999987\n",
      "epochs: 115, code: 300\n",
      "epochs: 115, code: 399005\n",
      "epochs: 115, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 116, code: 990905\n",
      "epochs: 116, code: 999987\n",
      "epochs: 116, code: 300\n",
      "epochs: 116, code: 399005\n",
      "epochs: 116, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 117, code: 990905\n",
      "epochs: 117, code: 999987\n",
      "epochs: 117, code: 300\n",
      "epochs: 117, code: 399005\n",
      "epochs: 117, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 118, code: 990905\n",
      "epochs: 118, code: 999987\n",
      "epochs: 118, code: 300\n",
      "epochs: 118, code: 399005\n",
      "epochs: 118, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 119, code: 990905\n",
      "epochs: 119, code: 999987\n",
      "epochs: 119, code: 300\n",
      "epochs: 119, code: 399005\n",
      "epochs: 119, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 120, code: 990905\n",
      "epochs: 120, code: 999987\n",
      "epochs: 120, code: 300\n",
      "epochs: 120, code: 399005\n",
      "epochs: 120, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 121, code: 990905\n",
      "epochs: 121, code: 999987\n",
      "epochs: 121, code: 300\n",
      "epochs: 121, code: 399005\n",
      "epochs: 121, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 122, code: 990905\n",
      "epochs: 122, code: 999987\n",
      "epochs: 122, code: 300\n",
      "epochs: 122, code: 399005\n",
      "epochs: 122, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 123, code: 990905\n",
      "epochs: 123, code: 999987\n",
      "epochs: 123, code: 300\n",
      "epochs: 123, code: 399005\n",
      "epochs: 123, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 124, code: 990905\n",
      "epochs: 124, code: 999987\n",
      "epochs: 124, code: 300\n",
      "epochs: 124, code: 399005\n",
      "epochs: 124, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 125, code: 990905\n",
      "epochs: 125, code: 999987\n",
      "epochs: 125, code: 300\n",
      "epochs: 125, code: 399005\n",
      "epochs: 125, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 126, code: 990905\n",
      "epochs: 126, code: 999987\n",
      "epochs: 126, code: 300\n",
      "epochs: 126, code: 399005\n",
      "epochs: 126, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 127, code: 990905\n",
      "epochs: 127, code: 999987\n",
      "epochs: 127, code: 300\n",
      "epochs: 127, code: 399005\n",
      "epochs: 127, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 128, code: 990905\n",
      "epochs: 128, code: 999987\n",
      "epochs: 128, code: 300\n",
      "epochs: 128, code: 399005\n",
      "epochs: 128, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 129, code: 990905\n",
      "epochs: 129, code: 999987\n",
      "epochs: 129, code: 300\n",
      "epochs: 129, code: 399005\n",
      "epochs: 129, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 130, code: 990905\n",
      "epochs: 130, code: 999987\n",
      "epochs: 130, code: 300\n",
      "epochs: 130, code: 399005\n",
      "epochs: 130, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 131, code: 990905\n",
      "epochs: 131, code: 999987\n",
      "epochs: 131, code: 300\n",
      "epochs: 131, code: 399005\n",
      "epochs: 131, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 132, code: 990905\n",
      "epochs: 132, code: 999987\n",
      "epochs: 132, code: 300\n",
      "epochs: 132, code: 399005\n",
      "epochs: 132, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 133, code: 990905\n",
      "epochs: 133, code: 999987\n",
      "epochs: 133, code: 300\n",
      "epochs: 133, code: 399005\n",
      "epochs: 133, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 134, code: 990905\n",
      "epochs: 134, code: 999987\n",
      "epochs: 134, code: 300\n",
      "epochs: 134, code: 399005\n",
      "epochs: 134, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 135, code: 990905\n",
      "epochs: 135, code: 999987\n",
      "epochs: 135, code: 300\n",
      "epochs: 135, code: 399005\n",
      "epochs: 135, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 136, code: 990905\n",
      "epochs: 136, code: 999987\n",
      "epochs: 136, code: 300\n",
      "epochs: 136, code: 399005\n",
      "epochs: 136, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 137, code: 990905\n",
      "epochs: 137, code: 999987\n",
      "epochs: 137, code: 300\n",
      "epochs: 137, code: 399005\n",
      "epochs: 137, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 138, code: 990905\n",
      "epochs: 138, code: 999987\n",
      "epochs: 138, code: 300\n",
      "epochs: 138, code: 399005\n",
      "epochs: 138, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 139, code: 990905\n",
      "epochs: 139, code: 999987\n",
      "epochs: 139, code: 300\n",
      "epochs: 139, code: 399005\n",
      "epochs: 139, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 140, code: 990905\n",
      "epochs: 140, code: 999987\n",
      "epochs: 140, code: 300\n",
      "epochs: 140, code: 399005\n",
      "epochs: 140, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 141, code: 990905\n",
      "epochs: 141, code: 999987\n",
      "epochs: 141, code: 300\n",
      "epochs: 141, code: 399005\n",
      "epochs: 141, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 142, code: 990905\n",
      "epochs: 142, code: 999987\n",
      "epochs: 142, code: 300\n",
      "epochs: 142, code: 399005\n",
      "epochs: 142, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 143, code: 990905\n",
      "epochs: 143, code: 999987\n",
      "epochs: 143, code: 300\n",
      "epochs: 143, code: 399005\n",
      "epochs: 143, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 144, code: 990905\n",
      "epochs: 144, code: 999987\n",
      "epochs: 144, code: 300\n",
      "epochs: 144, code: 399005\n",
      "epochs: 144, code: 399006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/8 [==============>...............] - ETA: 0sepochs: 145, code: 990905\n",
      "epochs: 145, code: 999987\n",
      "epochs: 145, code: 300\n",
      "epochs: 145, code: 399005\n",
      "epochs: 145, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 146, code: 990905\n",
      "epochs: 146, code: 999987\n",
      "epochs: 146, code: 300\n",
      "epochs: 146, code: 399005\n",
      "epochs: 146, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 147, code: 990905\n",
      "epochs: 147, code: 999987\n",
      "epochs: 147, code: 300\n",
      "epochs: 147, code: 399005\n",
      "epochs: 147, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 148, code: 990905\n",
      "epochs: 148, code: 999987\n",
      "epochs: 148, code: 300\n",
      "epochs: 148, code: 399005\n",
      "epochs: 148, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 149, code: 990905\n",
      "epochs: 149, code: 999987\n",
      "epochs: 149, code: 300\n",
      "epochs: 149, code: 399005\n",
      "epochs: 149, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 150, code: 990905\n",
      "epochs: 150, code: 999987\n",
      "epochs: 150, code: 300\n",
      "epochs: 150, code: 399005\n",
      "epochs: 150, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 151, code: 990905\n",
      "epochs: 151, code: 999987\n",
      "epochs: 151, code: 300\n",
      "epochs: 151, code: 399005\n",
      "epochs: 151, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 152, code: 990905\n",
      "epochs: 152, code: 999987\n",
      "epochs: 152, code: 300\n",
      "epochs: 152, code: 399005\n",
      "epochs: 152, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 153, code: 990905\n",
      "epochs: 153, code: 999987\n",
      "epochs: 153, code: 300\n",
      "epochs: 153, code: 399005\n",
      "epochs: 153, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 154, code: 990905\n",
      "epochs: 154, code: 999987\n",
      "epochs: 154, code: 300\n",
      "epochs: 154, code: 399005\n",
      "epochs: 154, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 155, code: 990905\n",
      "epochs: 155, code: 999987\n",
      "epochs: 155, code: 300\n",
      "epochs: 155, code: 399005\n",
      "epochs: 155, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 156, code: 990905\n",
      "epochs: 156, code: 999987\n",
      "epochs: 156, code: 300\n",
      "epochs: 156, code: 399005\n",
      "epochs: 156, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 157, code: 990905\n",
      "epochs: 157, code: 999987\n",
      "epochs: 157, code: 300\n",
      "epochs: 157, code: 399005\n",
      "epochs: 157, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 158, code: 990905\n",
      "epochs: 158, code: 999987\n",
      "epochs: 158, code: 300\n",
      "epochs: 158, code: 399005\n",
      "epochs: 158, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 159, code: 990905\n",
      "epochs: 159, code: 999987\n",
      "epochs: 159, code: 300\n",
      "epochs: 159, code: 399005\n",
      "epochs: 159, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 160, code: 990905\n",
      "epochs: 160, code: 999987\n",
      "epochs: 160, code: 300\n",
      "epochs: 160, code: 399005\n",
      "epochs: 160, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 161, code: 990905\n",
      "epochs: 161, code: 999987\n",
      "epochs: 161, code: 300\n",
      "epochs: 161, code: 399005\n",
      "epochs: 161, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 162, code: 990905\n",
      "epochs: 162, code: 999987\n",
      "epochs: 162, code: 300\n",
      "epochs: 162, code: 399005\n",
      "epochs: 162, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 163, code: 990905\n",
      "epochs: 163, code: 999987\n",
      "epochs: 163, code: 300\n",
      "epochs: 163, code: 399005\n",
      "epochs: 163, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 164, code: 990905\n",
      "epochs: 164, code: 999987\n",
      "epochs: 164, code: 300\n",
      "epochs: 164, code: 399005\n",
      "epochs: 164, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 165, code: 990905\n",
      "epochs: 165, code: 999987\n",
      "epochs: 165, code: 300\n",
      "epochs: 165, code: 399005\n",
      "epochs: 165, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 166, code: 990905\n",
      "epochs: 166, code: 999987\n",
      "epochs: 166, code: 300\n",
      "epochs: 166, code: 399005\n",
      "epochs: 166, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 167, code: 990905\n",
      "epochs: 167, code: 999987\n",
      "epochs: 167, code: 300\n",
      "epochs: 167, code: 399005\n",
      "epochs: 167, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 168, code: 990905\n",
      "epochs: 168, code: 999987\n",
      "epochs: 168, code: 300\n",
      "epochs: 168, code: 399005\n",
      "epochs: 168, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 169, code: 990905\n",
      "epochs: 169, code: 999987\n",
      "epochs: 169, code: 300\n",
      "epochs: 169, code: 399005\n",
      "epochs: 169, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 170, code: 990905\n",
      "epochs: 170, code: 999987\n",
      "epochs: 170, code: 300\n",
      "epochs: 170, code: 399005\n",
      "epochs: 170, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 171, code: 990905\n",
      "epochs: 171, code: 999987\n",
      "epochs: 171, code: 300\n",
      "epochs: 171, code: 399005\n",
      "epochs: 171, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 172, code: 990905\n",
      "epochs: 172, code: 999987\n",
      "epochs: 172, code: 300\n",
      "epochs: 172, code: 399005\n",
      "epochs: 172, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 173, code: 990905\n",
      "epochs: 173, code: 999987\n",
      "epochs: 173, code: 300\n",
      "epochs: 173, code: 399005\n",
      "epochs: 173, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 174, code: 990905\n",
      "epochs: 174, code: 999987\n",
      "epochs: 174, code: 300\n",
      "epochs: 174, code: 399005\n",
      "epochs: 174, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 175, code: 990905\n",
      "epochs: 175, code: 999987\n",
      "epochs: 175, code: 300\n",
      "epochs: 175, code: 399005\n",
      "epochs: 175, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 176, code: 990905\n",
      "epochs: 176, code: 999987\n",
      "epochs: 176, code: 300\n",
      "epochs: 176, code: 399005\n",
      "epochs: 176, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 177, code: 990905\n",
      "epochs: 177, code: 999987\n",
      "epochs: 177, code: 300\n",
      "epochs: 177, code: 399005\n",
      "epochs: 177, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 178, code: 990905\n",
      "epochs: 178, code: 999987\n",
      "epochs: 178, code: 300\n",
      "epochs: 178, code: 399005\n",
      "epochs: 178, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 179, code: 990905\n",
      "epochs: 179, code: 999987\n",
      "epochs: 179, code: 300\n",
      "epochs: 179, code: 399005\n",
      "epochs: 179, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 180, code: 990905\n",
      "epochs: 180, code: 999987\n",
      "epochs: 180, code: 300\n",
      "epochs: 180, code: 399005\n",
      "epochs: 180, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 181, code: 990905\n",
      "epochs: 181, code: 999987\n",
      "epochs: 181, code: 300\n",
      "epochs: 181, code: 399005\n",
      "epochs: 181, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 182, code: 990905\n",
      "epochs: 182, code: 999987\n",
      "epochs: 182, code: 300\n",
      "epochs: 182, code: 399005\n",
      "epochs: 182, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 183, code: 990905\n",
      "epochs: 183, code: 999987\n",
      "epochs: 183, code: 300\n",
      "epochs: 183, code: 399005\n",
      "epochs: 183, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 184, code: 990905\n",
      "epochs: 184, code: 999987\n",
      "epochs: 184, code: 300\n",
      "epochs: 184, code: 399005\n",
      "epochs: 184, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 185, code: 990905\n",
      "epochs: 185, code: 999987\n",
      "epochs: 185, code: 300\n",
      "epochs: 185, code: 399005\n",
      "epochs: 185, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 186, code: 990905\n",
      "epochs: 186, code: 999987\n",
      "epochs: 186, code: 300\n",
      "epochs: 186, code: 399005\n",
      "epochs: 186, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 187, code: 990905\n",
      "epochs: 187, code: 999987\n",
      "epochs: 187, code: 300\n",
      "epochs: 187, code: 399005\n",
      "epochs: 187, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 188, code: 990905\n",
      "epochs: 188, code: 999987\n",
      "epochs: 188, code: 300\n",
      "epochs: 188, code: 399005\n",
      "epochs: 188, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 189, code: 990905\n",
      "epochs: 189, code: 999987\n",
      "epochs: 189, code: 300\n",
      "epochs: 189, code: 399005\n",
      "epochs: 189, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 190, code: 990905\n",
      "epochs: 190, code: 999987\n",
      "epochs: 190, code: 300\n",
      "epochs: 190, code: 399005\n",
      "epochs: 190, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 191, code: 990905\n",
      "epochs: 191, code: 999987\n",
      "epochs: 191, code: 300\n",
      "epochs: 191, code: 399005\n",
      "epochs: 191, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 192, code: 990905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 192, code: 999987\n",
      "epochs: 192, code: 300\n",
      "epochs: 192, code: 399005\n",
      "epochs: 192, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 193, code: 990905\n",
      "epochs: 193, code: 999987\n",
      "epochs: 193, code: 300\n",
      "epochs: 193, code: 399005\n",
      "epochs: 193, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 194, code: 990905\n",
      "epochs: 194, code: 999987\n",
      "epochs: 194, code: 300\n",
      "epochs: 194, code: 399005\n",
      "epochs: 194, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 195, code: 990905\n",
      "epochs: 195, code: 999987\n",
      "epochs: 195, code: 300\n",
      "epochs: 195, code: 399005\n",
      "epochs: 195, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 196, code: 990905\n",
      "epochs: 196, code: 999987\n",
      "epochs: 196, code: 300\n",
      "epochs: 196, code: 399005\n",
      "epochs: 196, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 197, code: 990905\n",
      "epochs: 197, code: 999987\n",
      "epochs: 197, code: 300\n",
      "epochs: 197, code: 399005\n",
      "epochs: 197, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 198, code: 990905\n",
      "epochs: 198, code: 999987\n",
      "epochs: 198, code: 300\n",
      "epochs: 198, code: 399005\n",
      "epochs: 198, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 199, code: 990905\n",
      "epochs: 199, code: 999987\n",
      "epochs: 199, code: 300\n",
      "epochs: 199, code: 399005\n",
      "epochs: 199, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 200, code: 990905\n",
      "epochs: 200, code: 999987\n",
      "epochs: 200, code: 300\n",
      "epochs: 200, code: 399005\n",
      "epochs: 200, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 201, code: 990905\n",
      "epochs: 201, code: 999987\n",
      "epochs: 201, code: 300\n",
      "epochs: 201, code: 399005\n",
      "epochs: 201, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 202, code: 990905\n",
      "epochs: 202, code: 999987\n",
      "epochs: 202, code: 300\n",
      "epochs: 202, code: 399005\n",
      "epochs: 202, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 203, code: 990905\n",
      "epochs: 203, code: 999987\n",
      "epochs: 203, code: 300\n",
      "epochs: 203, code: 399005\n",
      "epochs: 203, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 204, code: 990905\n",
      "epochs: 204, code: 999987\n",
      "epochs: 204, code: 300\n",
      "epochs: 204, code: 399005\n",
      "epochs: 204, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 205, code: 990905\n",
      "epochs: 205, code: 999987\n",
      "epochs: 205, code: 300\n",
      "epochs: 205, code: 399005\n",
      "epochs: 205, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 206, code: 990905\n",
      "epochs: 206, code: 999987\n",
      "epochs: 206, code: 300\n",
      "epochs: 206, code: 399005\n",
      "epochs: 206, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 207, code: 990905\n",
      "epochs: 207, code: 999987\n",
      "epochs: 207, code: 300\n",
      "epochs: 207, code: 399005\n",
      "epochs: 207, code: 399006\n",
      "4/8 [==============>...............] - ETA: 0sepochs: 208, code: 990905\n",
      "epochs: 208, code: 999987\n",
      "epochs: 208, code: 300\n",
      "epochs: 208, code: 399005\n",
      "epochs: 208, code: 399006\n"
     ]
    },
    {
     "ename": "InfluxDBClientError",
     "evalue": "400: {\"error\":\"partial write: unable to parse 'deeplearning.train5,code=999987,dtype=train,epoch=208 acc=0.49857954545454547,loss=nan 1504483429167874048': invalid number\\nunable to parse 'deeplearning.train5,code=300,dtype=train,epoch=208 acc=0.24342105263157895,loss=nan 1504483430109561088': invalid number\\nunable to parse 'deeplearning.train5,code=399005,dtype=train,epoch=208 acc=0.2578125,loss=nan 1504483430885304064': invalid number\\nunable to parse 'deeplearning.train5,code=399006,dtype=train,epoch=208 acc=0.27187499999999998,loss=nan 1504483431297190912': invalid number dropped=0\"}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInfluxDBClientError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-da92401db527>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-45-5e4314a797a7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_set, test_set, epochs, batch_size)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;31m# result = {'type': 'train', 'code': code, 'train_loss': (e, history.history['loss'][-1]), 'train_acc': (e, history.history['acc'][-1])}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mMySeriesHelper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0;31m# print(result)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mMySeriesHelper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.3/lib/python3.5/site-packages/influxdb/helper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kw)\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseries\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datapoints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0;34m>=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bulk_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.3/lib/python3.5/site-packages/influxdb/helper.py\u001b[0m in \u001b[0;36mcommit\u001b[0;34m(cls, client)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mrtn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_json_body_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrtn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.3/lib/python3.5/site-packages/influxdb/client.py\u001b[0m in \u001b[0;36mwrite_points\u001b[0;34m(self, points, time_precision, database, retention_policy, tags, batch_size, protocol)\u001b[0m\n\u001b[1;32m    454\u001b[0m                                       \u001b[0mdatabase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                                       \u001b[0mretention_policy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretention_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m                                       tags=tags, protocol=protocol)\n\u001b[0m\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.3/lib/python3.5/site-packages/influxdb/client.py\u001b[0m in \u001b[0;36m_write_points\u001b[0;34m(self, points, time_precision, database, retention_policy, tags, protocol)\u001b[0m\n\u001b[1;32m    504\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0mexpected_response_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m204\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m                 \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m             )\n\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.3/lib/python3.5/site-packages/influxdb/client.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, data, params, expected_response_code, protocol)\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0mexpected_response_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpected_response_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m             \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m         )\n\u001b[1;32m    304\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.3/lib/python3.5/site-packages/influxdb/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, url, method, params, data, expected_response_code, headers)\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mInfluxDBClientError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     def write(self, data, params=None, expected_response_code=204,\n",
      "\u001b[0;31mInfluxDBClientError\u001b[0m: 400: {\"error\":\"partial write: unable to parse 'deeplearning.train5,code=999987,dtype=train,epoch=208 acc=0.49857954545454547,loss=nan 1504483429167874048': invalid number\\nunable to parse 'deeplearning.train5,code=300,dtype=train,epoch=208 acc=0.24342105263157895,loss=nan 1504483430109561088': invalid number\\nunable to parse 'deeplearning.train5,code=399005,dtype=train,epoch=208 acc=0.2578125,loss=nan 1504483430885304064': invalid number\\nunable to parse 'deeplearning.train5,code=399006,dtype=train,epoch=208 acc=0.27187499999999998,loss=nan 1504483431297190912': invalid number dropped=0\"}\n"
     ]
    }
   ],
   "source": [
    "train(model, train_set, test_set, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def data_gen(t=0):\n",
    "#     cnt = 0\n",
    "#     while cnt < 1000:\n",
    "#         cnt += 1\n",
    "#         t += 0.1\n",
    "#         yield t, np.sin(2*np.pi*t) * np.exp(-t/10.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ani = animation.FuncAnimation(fig, run, data_gen, repeat=False, init_func=init)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train(model, train_set, test_set, 100, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# history = model.fit(train_X, train_Y, epochs=100, batch_size=batch_size, validation_data=(test_X, test_Y), verbose=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'], label='train')\n",
    "plt.plot(history.history['val_acc'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_Y=model.predict(x=test_X1,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_value = np.argmax(predict_Y,axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_set = idx300n.iloc[1800:2400, :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_t2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def class_argmax(x):\n",
    "    return np.argmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_set = test_t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_set['class']= test_set['class'].map(class_argmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmp_predict = pd.DataFrame()\n",
    "cmp_predict['class'] = test_set['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmp_predict['predict_class'] = predict_value.reshape((-1, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmp_predict['close'] = test_t2.loc[cmp_predict.index, 'close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmp_predict['diff'] = cmp_predict['predict_class'] - cmp_predict['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmp_predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmp_predict=cmp_predict.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmp_predict = cmp_predict.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmp_predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def color(x):\n",
    "    c = 'm'\n",
    "    if x < 0:\n",
    "        c = 'g'\n",
    "    elif x > 0:\n",
    "        c = 'r'\n",
    "    else:\n",
    "        c = 'b'\n",
    "    return c\n",
    "cmp_predict['color'] = cmp_predict['diff'].map(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmp_predict.plot(kind='scatter', x='index', y='close', s=60, c=cmp_predict.color, figsize=(21, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_t2['close'].head(600).plot.hist( bins=30, figsize=(21, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmp_predict.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmp_predict['predict_class'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmp_predict['class'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmp_predict['next_close'] = cmp_predict['close'].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmp_predict['profit'] = cmp_predict['next_close'] - cmp_predict['close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmp_predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_profit(x):\n",
    "    profit = 0\n",
    "    if x['predict_class'] == 2:\n",
    "        profit = x['profit']\n",
    "    elif x['predict_class'] == 0:\n",
    "        profit = -x['profit']\n",
    "    else:\n",
    "        profit = 0\n",
    "    return profit\n",
    "cmp_predict['predict_profit'] = cmp_predict.apply(predict_profit, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmp_predict['predict_profit'].cumsum().plot(figsize=(21, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmp_predict.head(400).tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmp_predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmp_predict[cmp_predict['predict_class']==2]['predict_profit'].cumsum().plot(figsize=(21, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmp_predict[cmp_predict['predict_class']==0]['predict_profit'].cumsum().plot(figsize=(21, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 性能评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 类预测比较"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 类分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# column: true_class predict_class\n",
    "def class_compare(df):\n",
    "    return pd.crosstab(df.true_class, df.predict_class, margins=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 利润"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# column: close signal\n",
    "def portfolio_return_ration(df, direction=\"both\"):\n",
    "    def profit(x):\n",
    "        # 归一化\n",
    "        x[x['signal'] < -1]['signal'] = -1\n",
    "        x[x['signal'] > 1]['signal'] = 1\n",
    "\n",
    "        if direction == \"long\":\n",
    "            x[x['signal'] < 0]['signal'] = 0\n",
    "        elif direction == \"short\":\n",
    "            x[x['signal'] > 0]['signal'] = 0\n",
    "            \n",
    "        x['profit'] = x['diff'] * x['signal']\n",
    "        return x\n",
    "\n",
    "    df_tmp = pd.DataFrame()\n",
    "    pre_close = df['close'].shift(1)\n",
    "    df_tmp['diff'] =  df['close'] - pre_close\n",
    "    df_tmp['signal'] = df['signal']\n",
    "    \n",
    "    df_tmp['profit'] = df.apply(profit, axis=1)\n",
    "    return (df_tmp['profit']+1).cumprod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(0, 20, 100)\n",
    "y = np.sin(x)\n",
    "z = x + 20 * y\n",
    "\n",
    "scaled_z = (x - x.min())\n",
    "colors = plt.cm.coolwarm(x)\n",
    "\n",
    "plt.scatter(x, y, marker='+', edgecolors=colors, s=150, linewidths=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
