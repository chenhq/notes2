{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用python库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from talib.abstract import *\n",
    "import seaborn as sbn\n",
    "sbn.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Variable\n",
    "timesteps = 32\n",
    "batch_size = 4\n",
    "units = 32\n",
    "data_dim = 4\n",
    "# div_class = [-0.003, 0.003]\n",
    "# div_class = [-0.5, -0.3, -0.1, 0.1, 0.3, 0.5]\n",
    "# num_classes = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_load():\n",
    "    data_dir = '../data/'\n",
    "    day_index1 = data_dir + '1day/index/2000_2009.csv'\n",
    "    day_index2 = data_dir + '1day/index/2010_2016.csv'\n",
    "    data1 = pd.read_csv(day_index1,encoding='gbk', parse_dates=['date'])\n",
    "    data2 = pd.read_csv(day_index2,encoding='gbk', parse_dates=['date'])\n",
    "    data = pd.concat([data1, data2])\n",
    "    data.set_index(['code', 'date'], inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(data, query_str, timesteps=0, batch_size=0):\n",
    "    match = data.query(query_str)\n",
    "    min_num = int(batch_size) * int(timesteps) \n",
    "    size = len(match)\n",
    "    m = int(size / min_num)\n",
    "    end_num = 0\n",
    "    if batch_size == 0 or timestemps == 0:\n",
    "        end_num = size\n",
    "    elif m < 1:\n",
    "        end_num = 0\n",
    "    else:\n",
    "        end_num = min_num * m\n",
    "    \n",
    "    print(\"data set: {0}:{1} of {2}\".format(0, end_num, size))\n",
    "    result = match.iloc[:end_num, :].copy()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据清理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_clean(data):\n",
    "    new_data = pd.DataFrame()\n",
    "    for column in ['open', 'high', 'low', 'close']:\n",
    "        new_data[column] = data[column] / 10000.0\n",
    "\n",
    "    # new_data.dropna(inplace=True)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据转换"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 转换函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 阴阳线\n",
    "def stick_type(x):\n",
    "    stick_type = -1\n",
    "    if x['close'] >= x['open']:\n",
    "        stick_type = 1\n",
    "    return stick_type\n",
    "\n",
    "# 上引线\n",
    "def up_line(x):\n",
    "    return x['high'] - x[['open','close']].max()\n",
    "\n",
    "# 下引线\n",
    "def down_line(x):\n",
    "    return x[['open','close']].min() - x['low']\n",
    "\n",
    "# 实体长度\n",
    "def body_size(x):\n",
    "    return x['close'] - x['open']\n",
    "\n",
    "def range_to_class(x):\n",
    "    cls = []\n",
    "    size = len(div_class)\n",
    "    n = -1;\n",
    "    if x < div_class[0]:\n",
    "        n = 1\n",
    "    elif x >= div_class[size-1]:\n",
    "        n = size + 1\n",
    "    else:    \n",
    "        for i in range(0, size-1):\n",
    "            if div_class[i] <= x < div_class[i+1]:\n",
    "                n = i + 2\n",
    "                # print(\"n=\", n)\n",
    "                break\n",
    "    if n >= 0:\n",
    "        for i in range(0, size+1):\n",
    "            if i == n - 1:\n",
    "                cls.append(1.0)\n",
    "            else:\n",
    "                cls.append(0.0)\n",
    "    else:\n",
    "        print(x)\n",
    "        print(\"Error: n less than 0\")\n",
    "    return cls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_dim = 8\n",
    "data_dim = data_dim + new_dim\n",
    "\n",
    "def data_transform(data):\n",
    "    new_data = pd.DataFrame()\n",
    "    pre_close = data['close'].shift(1)\n",
    "    for column in ['open', 'high', 'low', 'close']:\n",
    "        new_data[column] = (data[column] - pre_close) / pre_close\n",
    "        \n",
    "    # add new feature\n",
    "    new_data['stick_type'] = new_data.apply(stick_type, axis=1)\n",
    "    new_data['up_line'] = new_data.apply(up_line, axis=1)\n",
    "    new_data['down_line'] = new_data.apply(down_line, axis=1)\n",
    "    new_data['close_open'] = new_data.apply(body_size, axis=1)\n",
    "    \n",
    "    # macd\n",
    "    macd = MACD(data.astype({'close': \"double\"}), price='close')\n",
    "    \n",
    "    new_data = pd.concat([new_data, macd], axis=1)\n",
    "        \n",
    "    # classes\n",
    "    new_data['class'] = new_data['close'].shift(-1)\n",
    "    # new_data.dropna(inplace=True)\n",
    "    new_data.fillna(0, inplace=True)\n",
    "    new_data['class']= new_data['class'].map(range_to_class)\n",
    "        \n",
    "    # new_data.dropna(inplace=True)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    columns = ['open', 'high', 'low', 'close', 'stick_type', 'up_line', 'down_line', 'close_open']\n",
    "    for column in columns:\n",
    "        data[column] = data[column] * 100\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据重整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_reform(data, batch_size, timesteps):\n",
    "    print(\"shape: {0}\".format(data.shape))\n",
    "    size = len(data)\n",
    "    if size % (int(batch_size) * int(timesteps)) != 0:\n",
    "        print(\"data size not match, size: {0}, batch_size: {1}, timesteps: {2}\".format(size, batch_size, timesteps))\n",
    "        return None, None\n",
    "   \n",
    "    X, Y0 = data[:, :-1], data[:, -1]\n",
    "    \n",
    "    X = X.reshape((-1, timesteps, X.shape[1]))\n",
    "    \n",
    "    Y = np.array([np.array(y) for y in Y0])\n",
    "    \n",
    "    Y = Y.reshape((-1, timesteps, Y.shape[1]))\n",
    "    \n",
    "    print(\"X.shape: {0} Y.shape: {1}\".format(X.shape, Y.shape))\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_all = data_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx_dict = {'上证50': 999987, '沪深300': 300, '中证500': 990905, '中小板指': 399005, '创业板指': 399006}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: 创业板指\n",
      "Id: Int64Index([399006], dtype='int64', name='code')\n",
      "name: 中小板指\n",
      "Id: Int64Index([399005, 399329], dtype='int64', name='code')\n",
      "name: 上证50\n",
      "Id: Int64Index([999987], dtype='int64', name='code')\n",
      "name: 沪深300\n",
      "Id: Int64Index([300, 399300], dtype='int64', name='code')\n",
      "name: 中证500\n",
      "Id: Int64Index([990905, 999905], dtype='int64', name='code')\n"
     ]
    }
   ],
   "source": [
    "# 确认指数代码\n",
    "for idx_name in idx_dict:\n",
    "    print(\"name: {0}\".format(idx_name))\n",
    "    Id = data_all[data_all['name'] == idx_name].index.get_level_values('code').unique()\n",
    "    print(\"Id: {0}\".format(Id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "years = pd.date_range('1/1/2006', periods=11, freq='A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_stat(data, years, idx_dict):\n",
    "    idxes_des = pd.DataFrame()\n",
    "    for name in idx_dict:\n",
    "        # print(name)\n",
    "        code = idx_dict[name]\n",
    "        query_code = 'code=={0}'.format(code)\n",
    "        # print(\"query code: {0}\".format(query_code))\n",
    "        data_code = data.query(query_code)\n",
    "        data_code_c = data_clean(data_code)\n",
    "        data_code_t = data_transform(data_code_c)\n",
    "        idx_des = pd.DataFrame()\n",
    "        for year in years:\n",
    "            end_date = year\n",
    "            begin_date  = year.replace(month=1, day=1)\n",
    "            query_date = 'date>\"{0}\" & date < \"{1}\"'.format(begin_date, end_date)\n",
    "            # print(\"query date: {0}\".format(query_date))\n",
    "            data_code_year = data_code_t.query(query_date)\n",
    "            describe = data_code_year.close.describe()\n",
    "            df_describe = describe.to_frame().reset_index()\n",
    "            df_describe['date'] = year\n",
    "            idx_des = pd.concat([idx_des, df_describe])\n",
    "        idx_des = idx_des.pivot(index='date', columns='index', values='close')    \n",
    "        idx_des['code'] = code\n",
    "        idxes_des = pd.concat([idxes_des, idx_des])\n",
    "    return idxes_des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_stat = data_stat(data_all, years, idx_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_stat_d = data_stat.drop(['count', 'min', 'max', 'std'],axis=1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = data_stat_d.reset_index().set_index(['code', 'date'])\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(8, 6))\n",
    "t.loc[999987].plot(ax=axes[0, 0])\n",
    "t.loc[300].plot(ax=axes[0, 1])\n",
    "t.loc[990905].plot(ax=axes[1, 0])\n",
    "t.loc[399005].plot(ax=axes[1, 1])\n",
    "t.loc[399006].plot(ax=axes[2, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.layers import LSTM, Dense, Dropout, BatchNormalization, Activation\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "# input layer\n",
    "# activation='relu' \n",
    "# dropout=0.5\n",
    "# kernel_initializer=\"uniform\"\n",
    "model.add(LSTM(units, stateful=True, return_sequences=True, batch_input_shape=(batch_size, timesteps, data_dim), kernel_initializer=\"uniform\"))\n",
    "# hidden layer\n",
    "model.add(LSTM(units, return_sequences=True, stateful=True, dropout=0.5, kernel_initializer=\"uniform\"))\n",
    "model.add(LSTM(units, return_sequences=True, stateful=True, dropout=0.5, kernel_initializer=\"uniform\"))\n",
    "model.add(LSTM(units, return_sequences=True, stateful=True, dropout=0.5, kernel_initializer=\"uniform\"))\n",
    "\n",
    "# 回归问题\n",
    "# # output layer\n",
    "# # model.add(Dense(no_classes, activation='softmax'))\n",
    "# model.add(Dense(1, activation='sigmoid')) # or sigmoid?\n",
    "# # model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# model.compile(optimizer='RMSProp', loss='mse') #mse\n",
    "\n",
    "# 分类问题\n",
    "# output layer\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "# model.add(Dense(num_classes, kernel_initializer=\"uniform\"))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation('softmax'))\n",
    "\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "model.compile(optimizer=RMSprop(0.0005), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_set(data, codes, date_query, timesteps, batch_size):\n",
    "    test_set = {}\n",
    "    for code in codes:\n",
    "        query_str = 'code=={0} & {1}'.format(code, date_query)\n",
    "        data_match = get_data(data, timesteps, batch_size, query_str)\n",
    "        data_cleaned = data_clean(data_match)\n",
    "        data_transformed = data_transform(data_cleaned)\n",
    "        print(data_transformed.index[0])\n",
    "        print(data_transformed.index[-1])\n",
    "        test_set[code] = data_transformed\n",
    "    return test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_codes = ['990905', '999987']\n",
    "test_date_query = 'date>\"20141120\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_test_set = get_data_set(data_all, test_codes, test_date_query, timesteps, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#raw_test_set['999987'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = {}\n",
    "for code in raw_test_set:\n",
    "    test_set[code] = data_reform(normalize(raw_test_set[code]).values, batch_size, timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idxes = data_all.index.get_level_values('code').unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_map = {'上证50': 999987, '沪深300': 300, '中证500': 990905, '中小板指': 399005, '创业板指': 399006}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train sets\n",
    "train_codes = []\n",
    "for key in train_map:\n",
    "    train_codes.append(train_map[key])\n",
    "    \n",
    "train_date_query = 'date<\"20150101\"'\n",
    "\n",
    "raw_train_set = get_data_set(data_all, train_codes, train_date_query, timesteps, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_set[300].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = {}\n",
    "for code in raw_train_set:\n",
    "    train_set[code] = data_reform(normalize(raw_train_set[code]).values, batch_size, timesteps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from influxdb import InfluxDBClient\n",
    "from influxdb import SeriesHelper\n",
    "host = '183.136.205.102'\n",
    "port = 38086\n",
    "user = 'root'\n",
    "password = 'root'\n",
    "dbname = 'chq'\n",
    "\n",
    "myclient = InfluxDBClient(host, port, user, password, dbname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainid = 2\n",
    "class MySeriesHelper(SeriesHelper):\n",
    "    # Meta class stores time series helper configuration.\n",
    "    class Meta:\n",
    "        # The client should be an instance of InfluxDBClient.\n",
    "        client = myclient\n",
    "        # The series name must be a string. Add dependent fields/tags in curly brackets.\n",
    "        series_name = 'deeplearning.train' + str(trainid)\n",
    "        # Defines all the fields in this time series.\n",
    "        fields = ['loss', 'acc']\n",
    "        # Defines all the tags for the series.\n",
    "        tags = ['dtype', 'code', 'epoch']\n",
    "        # Defines the number of data points to store prior to writing on the wire.\n",
    "        bulk_size = 5\n",
    "        # autocommit must be set to True when using bulk_size\n",
    "        autocommit = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs =2000\n",
    "def train(model, train_set, test_set, epochs, batch_size):\n",
    "# def train():\n",
    "    for e in range(epochs):\n",
    "        for code in train_set:\n",
    "            print(\"epochs: {0}, code: {1}\".format(e, code))\n",
    "            train_X, train_Y = train_set[code]\n",
    "            # print(train_X.shape, train_Y.shape, test_X.shape, test_Y.shape)\n",
    "            # history = model.fit(train_X, train_Y, epochs=100, batch_size=batch_size, validation_data=(test_X, test_Y), verbose=1, shuffle=False)\n",
    "            history = model.fit(train_X, train_Y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n",
    "            model.reset_states()  \n",
    "            # result = {'type': 'train', 'code': code, 'train_loss': (e, history.history['loss'][-1]), 'train_acc': (e, history.history['acc'][-1])}\n",
    "            MySeriesHelper(dtype=\"train\", code=code, epoch = e, loss=history.history['loss'][-1], acc= history.history['acc'][-1])\n",
    "            # print(result)\n",
    "        MySeriesHelper.commit()\n",
    "            # yield result\n",
    "        for code in test_set:\n",
    "            test_X1, test_Y1 = test_set[code]\n",
    "            loss_and_metrics = model.evaluate(test_X1, test_Y1, batch_size=batch_size)\n",
    "            model.reset_states()\n",
    "            # result = {'type': 'test', 'code': code, 'test_loss': (e, loss_and_metrics[0]), 'test_acc': (e, loss_and_metrics[1])}\n",
    "            MySeriesHelper(dtype=\"test\", code=code, epoch = e, loss=loss_and_metrics[0], acc= loss_and_metrics[1])\n",
    "            # print(result)\n",
    "        MySeriesHelper.commit()\n",
    "            # yield result\n",
    "                # print(\"==================================\")\n",
    "                # print(\"loss_and_metrics: {0}\".format(loss_and_metrics))\n",
    "                # print(\"==================================\")\n",
    "\n",
    "#     def data_gen(t=0):\n",
    "#         cnt = 0\n",
    "#         while cnt < 1000:\n",
    "#             cnt += 1\n",
    "#             t += 0.1\n",
    "#             yield t, np.sin(2*np.pi*t) * np.exp(-t/10.)\n",
    "# ani = animation.FuncAnimation(fig, run, train, repeat=False, init_func=init)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, train_set, test_set, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def data_gen(t=0):\n",
    "#     cnt = 0\n",
    "#     while cnt < 1000:\n",
    "#         cnt += 1\n",
    "#         t += 0.1\n",
    "#         yield t, np.sin(2*np.pi*t) * np.exp(-t/10.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ani = animation.FuncAnimation(fig, run, data_gen, repeat=False, init_func=init)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train(model, train_set, test_set, 100, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# history = model.fit(train_X, train_Y, epochs=100, batch_size=batch_size, validation_data=(test_X, test_Y), verbose=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'], label='train')\n",
    "plt.plot(history.history['val_acc'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_Y=model.predict(x=test_X1,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_value = np.argmax(predict_Y,axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_set = idx300n.iloc[1800:2400, :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_t2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def class_argmax(x):\n",
    "    return np.argmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_set = test_t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_set['class']= test_set['class'].map(class_argmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmp_predict = pd.DataFrame()\n",
    "cmp_predict['class'] = test_set['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmp_predict['predict_class'] = predict_value.reshape((-1, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmp_predict['close'] = test_t2.loc[cmp_predict.index, 'close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmp_predict['diff'] = cmp_predict['predict_class'] - cmp_predict['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmp_predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmp_predict=cmp_predict.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmp_predict = cmp_predict.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmp_predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def color(x):\n",
    "    c = 'm'\n",
    "    if x < 0:\n",
    "        c = 'g'\n",
    "    elif x > 0:\n",
    "        c = 'r'\n",
    "    else:\n",
    "        c = 'b'\n",
    "    return c\n",
    "cmp_predict['color'] = cmp_predict['diff'].map(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmp_predict.plot(kind='scatter', x='index', y='close', s=60, c=cmp_predict.color, figsize=(21, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_t2['close'].head(600).plot.hist( bins=30, figsize=(21, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmp_predict.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmp_predict['predict_class'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmp_predict['class'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmp_predict['next_close'] = cmp_predict['close'].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmp_predict['profit'] = cmp_predict['next_close'] - cmp_predict['close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmp_predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_profit(x):\n",
    "    profit = 0\n",
    "    if x['predict_class'] == 2:\n",
    "        profit = x['profit']\n",
    "    elif x['predict_class'] == 0:\n",
    "        profit = -x['profit']\n",
    "    else:\n",
    "        profit = 0\n",
    "    return profit\n",
    "cmp_predict['predict_profit'] = cmp_predict.apply(predict_profit, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmp_predict['predict_profit'].cumsum().plot(figsize=(21, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmp_predict.head(400).tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmp_predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmp_predict[cmp_predict['predict_class']==2]['predict_profit'].cumsum().plot(figsize=(21, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmp_predict[cmp_predict['predict_class']==0]['predict_profit'].cumsum().plot(figsize=(21, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 性能评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 类预测比较"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 类分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# column: true_class predict_class\n",
    "def class_compare(df):\n",
    "    return pd.crosstab(df.true_class, df.predict_class, margins=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 利润"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# column: close signal\n",
    "def portfolio_return_ration(df, direction=\"both\"):\n",
    "    def profit(x):\n",
    "        # 归一化\n",
    "        x[x['signal'] < -1]['signal'] = -1\n",
    "        x[x['signal'] > 1]['signal'] = 1\n",
    "\n",
    "        if direction == \"long\":\n",
    "            x[x['signal'] < 0]['signal'] = 0\n",
    "        elif direction == \"short\":\n",
    "            x[x['signal'] > 0]['signal'] = 0\n",
    "            \n",
    "        x['profit'] = x['diff'] * x['signal']\n",
    "        return x\n",
    "\n",
    "    df_tmp = pd.DataFrame()\n",
    "    pre_close = df['close'].shift(1)\n",
    "    df_tmp['diff'] =  df['close'] - pre_close\n",
    "    df_tmp['signal'] = df['signal']\n",
    "    \n",
    "    df_tmp['profit'] = df.apply(profit, axis=1)\n",
    "    return (df_tmp['profit']+1).cumprod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(0, 20, 100)\n",
    "y = np.sin(x)\n",
    "z = x + 20 * y\n",
    "\n",
    "scaled_z = (x - x.min())\n",
    "colors = plt.cm.coolwarm(x)\n",
    "\n",
    "plt.scatter(x, y, marker='+', edgecolors=colors, s=150, linewidths=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
